{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "_Lecture 5_\n",
    "# Parallel computing (on CPUs) and performance assessment"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The goal of this lecture 5 is to introduce:\n",
    "- Performance limiters\n",
    "- Effective memory throughput metric $T_\\mathrm{eff}$"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Parallel computing on CPUs\n",
    "- Shared memory parallelisation"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Performance limiters\n",
    "\n",
    "### Hardware\n",
    "- Recent processors (CPUs and GPUs) have multiple (or many) cores\n",
    "- Recent processors use their parallelism to hide latency\n",
    "- Multi-core CPUs and GPUs share similar challenges"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Recall from lecture 1 (**why we do it**) ...*"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use **parallel computing** (to address this):\n",
    "- The \"memory wall\" in ~ 2004\n",
    "- Single-core to multi-core devices\n",
    "\n",
    "![mem_wall](./figures/l1_mem_wall.png)"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "GPUs are massively parallel devices\n",
    "- SIMD machine (programmed using threads - SPMD) ([more](https://safari.ethz.ch/architecture/fall2020/lib/exe/fetch.php?media=onur-comparch-fall2020-lecture24-simdandgpu-afterlecture.pdf))\n",
    "- Further increases the FLOPS vs Bytes gap\n",
    "\n",
    "![cpu_gpu_evo](./figures/l1_cpu_gpu_evo.png)"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Taking a look at a recent GPU and CPU:\n",
    "- Nvidia Tesla A100 GPU\n",
    "- AMD EPYC \"Rome\" 7282 (16 cores) CPU\n",
    "\n",
    "| Device         | TFLOP/s (FP64) | Memory BW TB/s |\n",
    "| :------------: | :------------: | :------------: |\n",
    "| Tesla A100     | 9.7            | 1.55           |\n",
    "| AMD EPYC 7282  | 0.7            | 0.085          |"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Current GPUs (and CPUs) can do many more computations in a given amount of time than they can access numbers from main memory."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Quantify the imbalance:\n",
    "\n",
    "$$ \\frac{\\mathrm{computation\\;peak\\;performance\\;[TFLOP/s]}}{\\mathrm{memory\\;access\\;peak\\;performance\\;[TB/s]}} Ã— \\mathrm{size\\;of\\;a\\;number\\;[Bytes]} $$"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "_(Theoretical peak performance values as specified by the vendors can be used)._"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Back to our hardware:\n",
    "\n",
    "| Device         | TFLOP/s (FP64) | Memory BW TB/s | Imbalance (FP64)     |\n",
    "| :------------: | :------------: | :------------: | :------------------: |\n",
    "| Tesla A100     | 9.7            | 1.55           | 9.7 / 1.55  Ã— 8 = 50 |\n",
    "| AMD EPYC 7282  | 0.7            | 0.085          | 0.7 / 0.085 Ã— 8 = 66 |\n",
    "\n",
    "\n",
    "_(here computed with double precision values)_"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Meaning:** we can do 50 (GPU) and 66 (CPU) floating point operations per number accessed from main memory. Floating point operations are \"for free\" when we work in memory-bounded regimes\n",
    "\n",
    "âž¡ Requires to re-think the numerical implementation and solution strategies"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### On the scientific application side\n",
    "\n",
    "- Most algorithms require only a few operations or FLOPS ...\n",
    "- ... compared to the amount of numbers or bytes accessed from main memory."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First derivative example $âˆ‚A / âˆ‚x$:"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we \"naively\" compare the \"cost\" of an isolated evaluation of a finite-difference first derivative, e.g., computing a flux $q$:\n",
    "\n",
    "$$q = -D~\\frac{âˆ‚A}{âˆ‚x}~,$$\n",
    "\n",
    "which in the discrete form reads `q[ix] = -D*(A[ix+1]-A[ix])/dx`."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The cost of evaluating `q[ix] = -D*(A[ix+1]-A[ix])/dx`:\n",
    "\n",
    "1 reads + 1 write => $2 Ã— 8$ = **16 Bytes transferred**\n",
    "\n",
    "1 (fused) addition and division => **1 floating point operation**"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "assuming:\n",
    "- $D$, $âˆ‚x$ are scalars\n",
    "- $q$ and $A$ are arrays of `Float64` (read from main memory)"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "GPUs and CPUs perform 50 - 60 floating-point operations per number accessed from main memory\n",
    "\n",
    "First derivative evaluation requires to transfer 2 numbers per floating-point operations"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The FLOPS metric is no longer the most adequate for reporting the application performance of many modern applications on modern hardware."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Effective memory throughput metric $T_\\mathrm{eff}$\n",
    "\n",
    "Need for a memory throughput-based performance evaluation metric: $T_\\mathrm{eff}$ [GB/s]\n",
    "\n",
    "âž¡ Evaluate the performance of iterative stencil-based solvers."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The effective memory access $A_\\mathrm{eff}$ [GB]\n",
    "\n",
    "Sum of:\n",
    "- twice the memory footprint of the unknown fields, $D_\\mathrm{u}$, (fields that depend on their own history and that need to be updated every iteration)\n",
    "- known fields, $D_\\mathrm{k}$, that do not change every iteration."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The effective memory access divided by the execution time per iteration, $t_\\mathrm{it}$ [sec], defines the effective memory throughput, $T_\\mathrm{eff}$ [GB/s]:\n",
    "\n",
    "$$ A_\\mathrm{eff} = 2~D_\\mathrm{u} + D_\\mathrm{k} $$\n",
    "\n",
    "$$ T_\\mathrm{eff} = \\frac{A_\\mathrm{eff}}{t_\\mathrm{it}} $$"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The upper bound of $T_\\mathrm{eff}$ is $T_\\mathrm{peak}$ as measured, e.g., by [McCalpin, 1995](https://www.researchgate.net/publication/51992086_Memory_bandwidth_and_machine_balance_in_high_performance_computers) for CPUs or a GPU analogue.\n",
    "\n",
    "Defining the $T_\\mathrm{eff}$ metric, we assume that:\n",
    "1. we evaluate an iterative stencil-based solver,\n",
    "2. the problem size is much larger than the cache sizes and\n",
    "3. the usage of time blocking is not feasible or advantageous (reasonable for real-world applications)."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ðŸ’¡ note: Fields within the effective memory access that do not depend on their own history; such fields can be re-computed on the fly or stored on-chip."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As first task, we'll compute the $T_\\mathrm{eff}$ for the 2D fluid pressure (diffusion) solver at the core of the porous convection algorithm from previous lecture.\n",
    "\n",
    "ðŸ‘‰ Download the script [`l5_Pf_diffusion_2D.jl`](https://github.com/eth-vaw-glaciology/course-101-0250-00/blob/main/scripts/) to get started."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**To-do list:**\n",
    "- copy [`l5_Pf_diffusion_2D.jl`](https://github.com/eth-vaw-glaciology/course-101-0250-00/blob/main/scripts/), rename it to `Pf_diffusion_2D_Teff.jl`\n",
    "- add a timer\n",
    "- include the performance metric formulas\n",
    "- deactivate visualisation\n",
    "\n",
    "ðŸ’» Let's get started"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Timer and performance\n",
    "- Use `Base.time()` to return the current timestamp\n",
    "- Define `t_tic`, the starting time, after 11 iterations steps to allow for \"warm-up\"\n",
    "- Record the exact number of iterations (introduce e.g. `niter`)\n",
    "- Compute the elapsed time `t_toc` at the end of the time loop and report:"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "t_toc = ...\n",
    "A_eff = ...          # Effective main memory access per iteration [GB]\n",
    "t_it  = ...          # Execution time per iteration [s]\n",
    "T_eff = A_eff/t_it   # Effective memory throughput [GB/s]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Report `t_toc`, `T_eff` and `niter` at the end of the code, formatting output using `@printf()` macro.\n",
    "- Round `T_eff` to the 3rd significant digit.\n",
    "\n",
    "```julia\n",
    "@printf(\"Time = %1.3f sec, ... \\n\", t_toc, ...)\n",
    "```"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deactivate visualisation (and error checking)\n",
    "- Use keyword arguments (\"kwargs\") to allow for default behaviour\n",
    "- Define a `do_check` flag set to `false`"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function Pf_diffusion_2D(;??)\n",
    "    ...\n",
    "    return\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "So far so good, we have now a timer.\n",
    "\n",
    "Let's also boost resolution to `nx = ny = 511` and set `maxiter = max(nx,ny)` to have the code running ~1 sec.\n",
    "\n",
    "In the next part, we'll work on a multi-threading implementation."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parallel computing on CPUs\n",
    "\n",
    "_Towards implementing shared memory parallelisation using multi-threading capabilities of modern multi-core CPUs._"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll work it out in 3 steps:\n",
    "1. Precomputing scalars, removing divisions (and non-necessary arrays)\n",
    "2. Back to loops I\n",
    "3. Back to loops II - compute functions (future \"kernels\")"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Precomputing scalars, removing divisions and casual arrays\n",
    "\n",
    "Let's duplicate `Pf_diffusion_2D_Teff.jl` and rename it as `Pf_diffusion_2D_perf.jl`."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- First, replace `k_Î·f/dx` and `k_Î·f/dy` in the flux calculations by inverse multiplications, such that"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "k_Î·f_dx, k_Î·f_dy = k_Î·f/dx, k_Î·f/dy"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Then, replace divisions `./(1.0 + Î¸_dÏ„)` by inverse multiplications `*_1_Î¸_dÏ„` such that"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "_1_Î¸_dÏ„ = 1.0./(1.0 + Î¸_dÏ„)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Then, replace `./dx` and `./dy` in the `Pf` update by inverse multiplications `*_dx, *_dy` where"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "_dx, _dy = 1.0/dx, 1.0/dy"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Finally, also apply the same treatment to `./Î²_dÏ„`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Back to loops I\n",
    "\n",
    "As first, duplicate `Pf_diffusion_2D_perf.jl` and rename it as `Pf_diffusion_2D_perf_loop.jl`.\n",
    "\n",
    "The goal is now to write out the diffusion physics in a loop fashion over $x$ and $y$ dimensions."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implement a nested loop, taking car of bounds and staggering."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "for iy=??\n",
    "    for ix=??\n",
    "        qDx[??] -= (qDx[??] + k_Î·f_dx* ?? )*_1_Î¸_dÏ„\n",
    "    end\n",
    "end\n",
    "for iy=??\n",
    "    for ix=??\n",
    "        qDy[??] -= (qDy[??] + k_Î·f_dy* ?? )*_1_Î¸_dÏ„\n",
    "    end\n",
    "end\n",
    "for iy=??\n",
    "    for ix=??\n",
    "        Pf[??]  -= ??\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We could now use macros to make the code nicer and clearer. Macro expression will be replaced during pre-processing (prior to compilation). Also, macro can take arguments by appending `$` in their definition.\n",
    "\n",
    "Let's use macros to replace the derivative implementations"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "macro d_xa(A)  esc(:( $A[??]-$A[??] )) end\n",
    "macro d_ya(A)  esc(:( $A[??]-$A[??] )) end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "And update the code within the iteration loop:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "for iy=??\n",
    "    for ix=??\n",
    "        qDx[??] -= (qDx[??] + k_Î·f_dx* ?? )*_1_Î¸_dÏ„\n",
    "    end\n",
    "end\n",
    "for iy=??\n",
    "    for ix=??\n",
    "        qDy[??] -= (qDy[??] + k_Î·f_dy* ?? )*_1_Î¸_dÏ„\n",
    "    end\n",
    "end\n",
    "for iy=??\n",
    "    for ix=??\n",
    "        Pf[??]  -= ??\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Performance is already quite better with the loop version ðŸš€.\n",
    "\n",
    "Reasons are that `diff()` are allocating and that Julia is overall well optimised for executing loops.\n",
    "\n",
    "Let's now implement the final step."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Back to loops II\n",
    "\n",
    "Duplicate `Pf_diffusion_2D_perf_loop.jl` and rename it as `Pf_diffusion_2D_perf_loop_fun.jl`."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this last step, the goal is to define `compute` functions to hold the physics calculations, and to call those within the time loop."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a `compute_flux!()` and `compute_Pf!()` functions that take input and output arrays and needed scalars as argument and return nothing."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function compute_flux!(...)\n",
    "    nx,ny=size(Pf)\n",
    "    ...\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function update_Pf!(Pf,...)\n",
    "    nx,ny=size(Pf)\n",
    "    ...\n",
    "    return nothing\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ðŸ’¡ note: Functions that modify arguments take a `!` in their name, a Julia convention."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `compute_flux!()` and `compute_Pf!()` functions can then be called within the time loop.\n",
    "\n",
    "This last implementation executes a bit faster as previous one, as functions allow Julia to further optimise during just-ahead-of-time compilation."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ðŸ’¡ note: For optimal performance assessment, bound-checking should be deactivated. This can be achieved by adding `@inbounds` in front of the compute statement, or running the scripts (or launching Julia) with the `--check-bounds=no` option."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Various timing and benchmarking tools are available in Julia's ecosystem to [track performance issues](https://docs.julialang.org/en/v1/manual/performance-tips/). Julia's `Base` exposes the `@time` macro which returns timing and allocation estimation. [BenchmarkTools.jl](https://github.com/JuliaCI/BenchmarkTools.jl) package provides finer grained timing and benchmarking tooling, namely the `@btime`, `@belapsed` and `@benchmark` macros, among others."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's evaluate the performance of our code using `BenchmarkTools`. We will need to wrap the two compute kernels into a `compute!()` function in order to be able to call that one using `@belapsed`. Query `? @belapsed` in Julia's REPL to know more."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `compute!()` function:"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function compute!(Pf,qDx,qDy, ???)\n",
    "    compute_flux!(...)\n",
    "    update_Pf!(...)\n",
    "    return nothing\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "can then be called using `@belapsed` to return elapsed time for a single iteration, letting `BenchmarkTools` taking car about sampling"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "t_toc = @belapsed compute!($Pf,$qDx,$qDy,???)\n",
    "niter = ???"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ðŸ’¡ note: Variables need to be interpolated into the function call, thus taking a `$` in front."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Shared memory parallelisation\n",
    "\n",
    "Julia ships with it's `Base` feature the possibility to enable [multi-threading](https://docs.julialang.org/en/v1/manual/multi-threading/)."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The only 2 modifications needed to enable it in our code are:\n",
    "1. Place `Threads.@threads` in front of the outer loop definition\n",
    "2. Export the desired amount of threads, e.g., `export JULIA_NUM_THREADS=4`, to be activate prior to launching Julia (or executing the script from the shell). You can also launch Julia with `-t` option setting the desired numbers of threads. Setting `-t auto` will most likely automatically use as many hardware threads as available on a machine."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The number of threads can be queried within a Julia session as following: `Threads.nthreads()`"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ðŸ’¡ note: For optimal performance, the numbers of threads should be identical to the  number of physical cores of the target CPU (hardware threads)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-threading and AVX (ðŸš§ currently refactored)\n",
    "\n",
    "Relying on Julia's [LoopVectorization.jl](https://github.com/JuliaSIMD/LoopVectorization.jl) package, it is possible to combine multi-threading with [advanced vector extensions (AVX)](https://en.wikipedia.org/wiki/Advanced_Vector_Extensions) optimisations, leveraging extensions to the x86 instruction set architecture."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To enable it:\n",
    "1. Add `using LoopVectorization` at the top of the script\n",
    "2. Replace `Threads.@threads` by `@tturbo`\n",
    "\n",
    "And here we go ðŸš€"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wrapping-up\n",
    "\n",
    "- We discussed main performance limiters\n",
    "- We implemented the effective memory throughput metric $T_\\mathrm{eff}$\n",
    "- We optimised the Julia 2D diffusion code (multi-threading and AVX)"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  },
  "kernelspec": {
   "name": "julia-1.8",
   "display_name": "Julia 1.8.2",
   "language": "julia"
  }
 },
 "nbformat": 4
}
