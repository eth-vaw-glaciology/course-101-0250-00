<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <script src="/libs/lunr/lunr.min.js"></script> <script src="/libs/lunr/lunr_index.js"></script> <script src="/libs/lunr/lunrclient.min.js"></script> <link rel=stylesheet  href="/libs/highlight/github.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/poole_hyde.css"> <link rel=stylesheet  href="/css/custom.css"> <style> html {font-size: 17px;} .franklin-content {position: relative; padding-left: 8%; padding-right: 5%; line-height: 1.35em;} @media (min-width: 940px) { .franklin-content {width: 100%; margin-left: auto; margin-right: auto;} } @media (max-width: 768px) { .franklin-content {padding-left: 6%; padding-right: 6%;} } </style> <link rel=icon  href="/assets/favicon.png"> <title>Software install</title> <style> .content {max-width: 50rem} </style> <div class=sidebar > <div class="container sidebar-sticky"> <div class=sidebar-about > <img src="/assets/vaw_logo.png" style="width: 180px; height: auto; display: inline"> <div style="margin-bottom: 0.5em"><a href="/"> Fall 2025</a> <span style="opacity: 0.7;">| <a href=https://www.vorlesungen.ethz.ch/Vorlesungsverzeichnis/lerneinheit.view?semkez=2025W&ansicht=KATALOGDATEN&lerneinheitId=193496&lang=en> ETHZ 101-0250-00</a></span></div> <br> <h1><a href="/">Solving partial differential equations in parallel on GPUs I</a></h1> <div style="line-height:18px; font-size: 15px; opacity: 0.85">by &nbsp; <a href="https://vaw.ethz.ch/en/people/person-detail.MjcwOTYw.TGlzdC8xOTYxLDE1MTczNjI1ODA=.html">Ludovic R√§ss</a>, &nbsp; <a href="https://vaw.ethz.ch/en/personen/person-detail.html?persid=124402">Mauro Werder</a>, &nbsp; <a href="https://www.cscs.ch/about/staff/">Samuel Omlin</a> & <br> <a href="https://vaw.ethz.ch/en/people/person-detail.MzAwMjIy.TGlzdC8xOTYxLDE1MTczNjI1ODA=.html">Ivan Utkin</a> </div> </div> <br> <style> </style> <nav class=sidebar-nav  style="opacity: 0.9; margin-bottom: 1cm;"> <a class="sidebar-nav-item " href="/"><b>Welcome</b></a> <a class="sidebar-nav-item " href="/logistics/">Logistics</a> <a class="sidebar-nav-item " href="/homework/">Homeworks</a> <a class="sidebar-nav-item active" href="/software_install/">Software install</a> <a class="sidebar-nav-item " href="/extras/">Extras</a> <br> <div class=course-section >Part 1 ‚Äì Introduction</div> <a class="sidebar-nav-item " href="/lecture1/">Lecture 1 ‚Äì Introduction to Julia</a> <a class="sidebar-nav-item " href="/lecture2/">Lecture 2 ‚Äì PDEs & physical processes</a> <a class="sidebar-nav-item " href="/lecture3/"> Lecture 3 ‚Äì Solving elliptic PDEs</a> <a class="sidebar-nav-item " href="/lecture4/">Lecture 4 ‚Äì Coupled multi-physics</a> <div class=course-section >Part 2 ‚Äì Solving PDEs on GPUs</div> <a class="sidebar-nav-item " href="/lecture5/">Lecture 5 ‚Äì Porous convection</a> <a class="sidebar-nav-item " href="/lecture6/">Lecture 6 ‚Äì Parallel computing</a> <a class="sidebar-nav-item " href="/lecture7/">Lecture 7 ‚Äì GPU computing</a> <a class="sidebar-nav-item " href="/lecture8/">Lecture 8 ‚Äì xPU computing</a> <div class=course-section >Part 3 ‚Äì Multi-GPU computing (projects)</div> <a class="sidebar-nav-item " href="/lecture9/">Lecture 9 ‚Äì Julia MPI & multi-xPU</a> <a class="sidebar-nav-item " href="/lecture10/">Lecture 10 ‚Äì ImplicitGlobalGrid.jl</a> <div class="sidebar-nav-item under-construction"> Lecture 11 ‚Äì Multi-xPU & Projects</div> <div class="sidebar-nav-item under-construction"> Lecture 12 ‚Äì Advanced optimisations</div> </nav> <form id=lunrSearchForm  name=lunrSearchForm > <input class=search-input  name=q  placeholder="Enter search term" type=text > <input type=submit  value=Search  formaction="/search/index.html"> </form> <br> <br> </div> </div> <div class="content container"> <div class=franklin-content > <h1 id=software_install ><a href="#software_install" class=header-anchor >Software install</a></h1> <div class=franklin-toc ><ol><li><a href="#software_install">Software install</a><ol><li><a href="#opening_and_running_the_jupyter_julia_notebook">Opening and running the Jupyter Julia notebook</a><li><a href="#jupyterhub">JupyterHub</a><li><a href="#installing_julia_v111_or_later">Installing Julia v1.11 &#40;or later&#41;</a><li><a href="#running_julia">Running Julia</a><li><a href="#gpu_computing_on_alps">GPU computing on Alps</a></ol></ol></div> <h2 id=opening_and_running_the_jupyter_julia_notebook ><a href="#opening_and_running_the_jupyter_julia_notebook" class=header-anchor >Opening and running the Jupyter Julia notebook</a></h2> <h3 id=course_slides_and_lecture_material ><a href="#course_slides_and_lecture_material" class=header-anchor >Course slides and lecture material</a></h3> <p>All the course slides are <a href="https://jupyter.org/">Jupyter notebooks</a>; browser-based computational notebooks.</p> <p>Code cells are executed by putting the cursor into the cell and hitting <code>shift &#43; enter</code>. For more info see the <a href="https://jupyter-notebook.readthedocs.io/en/stable/">documentation</a>.</p> <h3 id=exercises_and_homework ><a href="#exercises_and_homework" class=header-anchor >Exercises and homework</a></h3> <p>The first two lecture&#39;s homework assignments will be <a href="https://jupyter.org/">Jupyter notebooks</a>. You can import the notebooks from Moodle into your JupyterHub space. You can execute them on the <a href="https://moodle-app2.let.ethz.ch/mod/lti/view.php?id=1275858">JupyterHub</a> or download them and run them them locally if you&#39;re already set-up.</p> <p>For submission, you can directly submit the folder containing all notebooks of a lecture from within the JupyterHub/Moodle integration. From the homework task on Moodle, you should be able to launch the notebooks in your JupyterHub. Once the homework completed, you should be able to see the folders you have worked on from your JupyterHub within the submission steps on Moodle. See <a href="/logistics">Logistics</a> and <a href="/homework">Homework</a> for details.</p> <p>Starting from lecture 3, exercise scripts will be mostly standalone regular Julia scripts that have to be uploaded to your private GitHub repo &#40;shared with the teaching staff only&#41;. Details in <a href="/logistics/#submission">Logistics</a>.</p> <h2 id=jupyterhub ><a href="#jupyterhub" class=header-anchor >JupyterHub</a></h2> <p>You can access the JupyterHub from the <strong>General</strong> section in <a href="https://moodle-app2.let.ethz.ch/course/view.php?id=26390">Moodle</a>, clicking on <a href="https://moodle-app2.let.ethz.ch/mod/lti/view.php?id=1275858"><img src="/assets/JHub2.png#badge" alt=JupyterHub  /></a></p> <p>Upon login to the server, you should see the following launcher environment, including a notebook &#40;file&#41; browser, ability to create a notebook, launch a Julia console &#40;REPL&#41;, or a regular terminal.</p> <p><img src="/assets/JHubLauncher.png" alt=JupyterHub  /></p> <div class=warning ><div class=title >‚ö†Ô∏è Warning&#33;</div> <div class=messg >It is recommended to download your work as back-up before leaving the session.</div></div> <h2 id=installing_julia_v111_or_later ><a href="#installing_julia_v111_or_later" class=header-anchor >Installing Julia v1.11 &#40;or later&#41;</a></h2> <h3 id=juliaup_installer ><a href="#juliaup_installer" class=header-anchor >Juliaup installer</a></h3> <p>Follow the instructions from the <a href="https://julialang.org/downloads/">Julia Download page</a> to install Julia v1.11 &#40;which is using the <a href="https://github.com/JuliaLang/juliaup"><strong>Juliaup</strong></a> Julia installer under the hood&#41;.</p> <div class=note ><div class=title >üí° Note</div> <div class=messg ><em><strong>For Windows users:</strong></em> When installing Julia 1.11 on Windows, make sure to check the &quot;Add PATH&quot; tick or ensure Julia is on PATH &#40;see <strong>&#91;help&#93;</strong>&#41;. Julia&#39;s REPL has a built-in shell mode you can access typing <code>;</code> that natively works on Unix-based systems. On Windows, you can access the Windows shell by typing <code>Powershell</code> within the shell mode, and exit it typing <code>exit</code>, as described <a href="https://docs.julialang.org/en/v1/stdlib/REPL/#man-shell-mode">here</a>.</div></div> <h3 id=terminal_external_editor ><a href="#terminal_external_editor" class=header-anchor >Terminal &#43; external editor</a></h3> <p>Ensure you have a text editor with syntax highlighting support for Julia. We recommend to use VSCode, see below. However, other editors are available too such as Sublime, Emacs, Vim, Helix, etc.</p> <p>From within the terminal, type</p> <pre><code class="sh hljs">julia</code></pre>
<p>to make sure that the Julia REPL &#40;aka terminal&#41; starts. Then you should be able to add <code>1&#43;1</code> and verify you get the expected result. Exit with <code>Ctrl-d</code>.</p>
<p><img src="/assets/julia_terminal.png" alt="Julia from Terminal" /></p>
<h3 id=vs_code ><a href="#vs_code" class=header-anchor >VS Code</a></h3>
<p>If you&#39;d enjoy a more IDE type of environment, <a href="https://code.visualstudio.com">check out VS Code</a>. Follow the <a href="https://github.com/julia-vscode/julia-vscode#getting-started">installation directions</a> for the <a href="https://www.julia-vscode.org">Julia VS Code extension</a>.</p>
<h4 id=vs_code_remote_-_ssh_setup ><a href="#vs_code_remote_-_ssh_setup" class=header-anchor >VS Code Remote - SSH setup</a></h4>
<p>VS Code&#39;s <a href="https://marketplace.visualstudio.com/items?itemName&#61;ms-vscode-remote.remote-ssh">Remote-SSH</a> extension allows you to connect and open a remote folder on any remote machine with a running SSH server. Once connected to a server, you can interact with files and folders anywhere on the remote filesystem &#40;<a href="https://code.visualstudio.com/docs/remote/ssh">more</a>&#41;.</p>
<ol>
<li><p>To get started, follow <a href="https://code.visualstudio.com/docs/remote/ssh#_installation">the install steps</a>.</p>

<li><p>Then, you can <a href="https://code.visualstudio.com/docs/remote/ssh#_connect-to-a-remote-host">connect to a remote host</a>, using <code>ssh user@hostname</code> and your password &#40;selecting <code>Remote-SSH: Connect to Host...</code> from the Command Palette&#41;.</p>

<li><p><a href="https://code.visualstudio.com/docs/remote/ssh#_remember-hosts-and-advanced-settings">Advanced options</a> permit you to <a href="#running_julia_interactively_on_alps">access a remote compute node from within VS Code</a>.</p>

</ol>
<div class=note ><div class=title >üí° Note</div>
<div class=messg >This remote configuration supports Julia graphics to render within VS Code&#39;s plot pane. However, this &quot;remote&quot; visualisation option is only functional when plotting from a Julia instance launched as <code>Julia: Start REPL</code> from the Command Palette. Displaying a plot from a Julia instance launched from the remote terminal &#40;which allows, e.g., to include custom options such as <code>ENV</code> variables or load modules&#41; will fail. To work around this limitation, select <code>Julia: Connect external REPL</code> from the Command Palette and follow the prompted instructions.</div></div>
<h2 id=running_julia ><a href="#running_julia" class=header-anchor >Running Julia</a></h2>
<h3 id=first_steps ><a href="#first_steps" class=header-anchor >First steps</a></h3>
<p>Now that you have a running Julia install, launch Julia &#40;e.g. by typing <code>julia</code> in the shell since it should be on path&#41;</p>
<pre><code class="sh hljs">julia</code></pre>
<p>Welcome in the <a href="https://docs.julialang.org/en/v1/stdlib/REPL/">Julia REPL</a> &#40;command window&#41;. There, you have 3 &quot;modes&quot;, the standard</p>
<pre><code class="julia-repl hljs">[user@comp ~]$ julia
               _
   _       _ _(_)_     |  Documentation: https://docs.julialang.org
  (_)     | (_) (_)    |
   _ _   _| |_  __ _   |  Type &quot;?&quot; for help, &quot;]?&quot; for Pkg help.
  | | | | | | |/ _` |  |
  | | |_| | | | (_| |  |  Version 1.11.6 (2025-07-09)
 _/ |\__&#x27;_|_|_|\__&#x27;_|  |  Official https://julialang.org/ release
|__/                   |

<span class="hljs-meta prompt_">julia&gt;</span></code></pre>
<p>the shell mode by hitting <code>;</code>, where you can enter Unix commands,</p>
<pre><code class="julia-repl hljs"><span class=hljs-metas>shell&gt;</span></code></pre>
<p>and the <a href="https://docs.julialang.org/en/v1/stdlib/REPL/#Pkg-mode">Pkg mode</a> &#40;package manager&#41; by hitting <code>&#93;</code>, that will be used to add and manage packages, and environments,</p>
<pre><code class="julia-repl hljs"><span class=hljs-metap>(@v1.11) pkg&gt;</span></code></pre>
<p>You can interactively execute commands in the REPL, like adding two numbers</p>
<pre><code class="julia-repl hljs"><span class="hljs-meta prompt_">julia&gt;</span><span class=language-julia > <span class=hljs-number >2</span>+<span class=hljs-number >2</span>
</span>4

<span class="hljs-meta prompt_">julia&gt;</span></code></pre>
<p>Within this class, we will mainly work with Julia scripts. You can run them using the <code>include&#40;&#41;</code> function in the REPL</p>
<pre><code class="julia-repl hljs"><span class="hljs-meta prompt_">julia&gt;</span><span class=language-julia > include(<span class=hljs-string >&quot;my_script.jl&quot;</span>)</span></code></pre>
<p>Alternatively, you can also execute a Julia script from the shell</p>
<pre><code class="sh hljs">julia -03 my_script.jl</code></pre>
<p>here passing the <code>-O3</code> optimisation flag.</p>
<h3 id=package_manager ><a href="#package_manager" class=header-anchor >Package manager</a></h3>
<p>The <a href="https://docs.julialang.org/en/v1/stdlib/REPL/#Pkg-mode">Pkg mode</a> permits you to install and manage Julia packages, and control the project&#39;s environment.</p>
<p>Environments or Projects are an efficient way that enable portability and reproducibility. Upon activating a local environment, you generate a local <code>Project.toml</code> file that stores the packages and version you are using within a specific project &#40;code-s&#41;, and a <code>Manifest.toml</code> file that keeps track locally of the state of the environment.</p>
<p>To activate an project-specific environment, navigate to your targeted project folder, launch Julia</p>
<pre><code class="sh hljs"><span class=hljs-built_in >mkdir</span> my_cool_project
<span class=hljs-built_in >cd</span> my_cool_project
julia</code></pre>
<p>and activate it</p>
<pre><code class="julia-repl hljs"><span class="hljs-meta prompt_">julia&gt;</span><span class=language-julia > ]
</span>
<span class=hljs-metap>(@v1.11) pkg&gt;</span>

<span class=hljs-metap>(@v1.11) pkg&gt;</span> activate .
  Activating new environment at `~/my_cool_project/Project.toml`

<span class=hljs-metap>(my_cool_project) pkg&gt;</span></code></pre>
<p>Then, let&#39;s install the <code>Plots.jl</code> package</p>
<pre><code class="julia-repl hljs"><span class=hljs-metap>(my_cool_project) pkg&gt;</span> add Plots</code></pre>
<p>and check the status</p>
<pre><code class="julia-repl hljs"><span class=hljs-metap>(my_cool_project) pkg&gt;</span> st
      Status `~/my_cool_project/Project.toml`
  [91a5bcdd] Plots v1.22.3</code></pre>
<p>as well as the <code>.toml</code> files</p>
<pre><code class="julia-repl hljs"><span class="hljs-meta prompt_">julia&gt;</span><span class=language-julia > ;
</span>
<span class=hljs-metas>shell&gt;</span> ls
Manifest.toml Project.toml</code></pre>
<p>We can now load <code>Plots.jl</code> and plot some random noise</p>
<pre><code class="julia-repl hljs"><span class="hljs-meta prompt_">julia&gt;</span><span class=language-julia > <span class=hljs-keyword >using</span> Plots
</span>
<span class="hljs-meta prompt_">julia&gt;</span><span class=language-julia > heatmap(rand(<span class=hljs-number >10</span>,<span class=hljs-number >10</span>))</span></code></pre>
<p>Let&#39;s assume you&#39;re handed your <code>my_cool_project</code> to someone to reproduce your cool random plot. To do so, you can open julia from the <code>my_cool_project</code> folder with the <code>--project</code> option</p>
<pre><code class="sh hljs"><span class=hljs-built_in >cd</span> my_cool_project
julia --project</code></pre>
<p>Or you can rather activate it afterwards</p>
<pre><code class="sh hljs"><span class=hljs-built_in >cd</span> my_cool_project
julia</code></pre>
<p>and then,</p>
<pre><code class="julia-repl hljs"><span class="hljs-meta prompt_">julia&gt;</span><span class=language-julia > ]
</span>
<span class=hljs-metap>(@v1.11) pkg&gt;</span> activate .
  Activating environment at `~/my_cool_project/Project.toml`

<span class=hljs-metap>(my_cool_project) pkg&gt;</span>

<span class=hljs-metap>(my_cool_project) pkg&gt;</span> st
      Status `~/my_cool_project/Project.toml`
  [91a5bcdd] Plots v1.40.20</code></pre>
<p>Here we go, you can now share that folder with colleagues or with yourself on another machine and have a reproducible environment üôÇ</p>
<h3 id=multi-threading_on_cpus ><a href="#multi-threading_on_cpus" class=header-anchor >Multi-threading on CPUs</a></h3>
<p>On the CPU, <a href="https://docs.julialang.org/en/v1/manual/multi-threading/#man-multithreading">multi-threading</a> is made accessible via <a href="https://docs.julialang.org/en/v1/base/multi-threading/">Base.Threads</a>. To make use of threads, Julia needs to be launched with</p>
<pre><code class="sh hljs">julia --project -t auto</code></pre>
<p>which will launch Julia with as many threads are there are cores on your machine &#40;including hyper-threaded cores&#41;. Alternatively set the environment variable <code>JULIA_NUM_THREADS</code>, e.g. <code>export JULIA_NUM_THREADS&#61;2</code> to enable 2 threads.</p>
<h3 id=julia_on_gpus ><a href="#julia_on_gpus" class=header-anchor >Julia on GPUs</a></h3>
<p>The <a href="https://github.com/JuliaGPU/CUDA.jl">CUDA.jl</a> module permits to launch compute kernels on Nvidia GPUs natively from within Julia. <a href="https://juliagpu.org">JuliaGPU</a> provides further reading and <a href="https://juliagpu.gitlab.io/CUDA.jl/tutorials/introduction/">introductory material</a> about GPU ecosystems within Julia.</p>
<h3 id=julia_mpi ><a href="#julia_mpi" class=header-anchor >Julia MPI</a></h3>
<p>The following steps permit you to install <a href="https://github.com/JuliaParallel/MPI.jl">MPI.jl</a> on your machine and test it:</p>
<ol>
<li><p>If Julia MPI is a dependency of a Julia project MPI.jl should have been added upon executing the <code>instantiate</code> command from within the package manager <a href="#package_manager">see here</a>. If not, MPI.jl can be added from within the package manager &#40;typing <code>add MPI</code> in package mode&#41;.</p>

<li><p>Install <code>mpiexecjl</code>:</p>

</ol>
<pre><code class="julia-repl hljs"><span class="hljs-meta prompt_">julia&gt;</span><span class=language-julia > <span class=hljs-keyword >using</span> MPI
</span>
<span class="hljs-meta prompt_">julia&gt;</span><span class=language-julia > MPI.install_mpiexecjl()
</span>[ Info: Installing `mpiexecjl` to `HOME/.julia/bin`...
[ Info: Done!</code></pre>
<ol start=3 >
<li><p>Then, one should add <code>HOME/.julia/bin</code> to PATH in order to launch the Julia MPI wrapper <code>mpiexecjl</code>.</p>

<li><p>Running a Julia MPI code <code>&lt;my_script.jl&gt;</code> on <code>np</code> MPI processes:</p>

</ol>
<pre><code class="sh hljs">$ mpiexecjl -n np julia --project &lt;my_script.jl&gt;</code></pre>
<ol start=5 >
<li><p>To test the Julia MPI installation, launch the <a href="https://github.com/eth-vaw-glaciology/course-101-0250-00/blob/main/scripts/"><code>l8_hello_mpi.jl</code></a> using the Julia MPI wrapper <code>mpiexecjl</code> &#40;located in <code>~/.julia/bin</code>&#41; on, e.g., 4 processes:</p>

</ol>
<pre><code class="sh hljs">$ mpiexecjl -n 4 julia --project ./l8_hello_mpi.jl
$ Hello world, I am 0 of 3
$ Hello world, I am 1 of 3
$ Hello world, I am 2 of 3
$ Hello world, I am 3 of 3</code></pre>
<div class=note ><div class=title >üí° Note</div>
<div class=messg ><p>On macOS, you may encounter <a href="https://github.com/JuliaParallel/MPI.jl/issues/407">this issue</a>. To fix it, define following <code>ENV</code> variable:</p>
<pre><code class="sh hljs">$ <span class=hljs-built_in >export</span> MPICH_INTERFACE_HOSTNAME=localhost</code></pre>
<p>and add <code>-host localhost</code> to the execution script:</p>
<pre><code class="sh hljs">$ mpiexecjl -n 4 -host localhost julia --project ./hello_mpi.jl</code></pre></div></div>
<h2 id=gpu_computing_on_alps ><a href="#gpu_computing_on_alps" class=header-anchor >GPU computing on Alps</a></h2>
<p>GPU computing on <a href="https://www.cscs.ch/computers/alps">Alps</a> at <a href="https://www.cscs.ch">CSCS</a>. The supercomputer Alps is composed of 2688 compute nodes, each hosting 4 Nvidia GH200 96GB GPUs. We have a 4000 node hour allocation for our course on the HPC Platform <strong>Daint</strong>, a versatile cluster &#40;vCluster&#41; within the Alps infrastructure.</p>
<div class=warning ><div class=title >‚ö†Ô∏è Warning&#33;</div>
<div class=messg >Since the course allocation is exceptional, make sure not to open any help tickets directly at CSCS help, but report questions and issue <em>exclusively</em> to our <strong>helpdesk</strong> room on Element. Also, better ask about good practice before launching anything you are unsure in order to avoid any disturbance on the machine.</div></div>
<p>The login procedure is as follow. First a login to the front-end &#40;or login&#41; machine Ela &#40;hereafter referred to as &quot;ela&quot;&#41; is needed before one can log into Daint. Login is performed using <code>ssh</code>. We will set-up a proxy-jump in order to simplify the procedure and directly access Daint &#40;hereafter referred to as &quot;daint&quot;&#41;</p>
<p>Both daint and ela share a <code>home</code> folder. However, the <code>scratch</code> folder is only accessible on daint. We can use VS code in combination with the proxy-jump to conveniently edit files on daint&#39;s scratch directly. We will use a Julia &quot;uenv&quot; to have all Julia-related tools ready.</p>
<p>Make sure to have the Remote-SSH extension installed in VS code <a href="#vs_code_remote_-_ssh_setup">&#40;see here for details on how-to&#41;</a>.</p>
<p>Please follow the steps listed hereafter to get ready and set-up on daint.</p>
<h3 id=account_setup ><a href="#account_setup" class=header-anchor >Account setup</a></h3>
<div class=warning ><div class=title >‚ö†Ô∏è Warning&#33;</div>
<div class=messg >The course accounts somewhat differ from regular account and do not require MFA. The connection procedure from CSCS&#39; user doc does thus not apply.</div></div>
<ol>
<li><p>Fetch your personal username and password credentials from Moodle.</p>

<li><p>Open a terminal &#40;in Windows, use a tool as e.g. <a href="">PuTTY</a> or <a href="https://learn.microsoft.com/en-us/windows-server/administration/openssh/openssh_install_firstuse?tabs&#61;gui">OpenSSH</a>&#41; and <code>ssh</code> to ela and enter the password:</p>

</ol>
<pre><code class="sh hljs">ssh &lt;username&gt;@ela.cscs.ch</code></pre>
<ol start=3 >
<li><p>Generate a <code>ed25519</code> keypair. On your local machine &#40;not ela&#41;, do <code>ssh-keygen</code> leaving the passphrase empty. Then copy your public key to the remote server &#40;ela&#41; using <code>ssh-copy-id</code>.</p>

</ol>
<pre><code class="sh hljs">ssh-keygen -t ed25519
ssh-copy-id -i ~/.ssh/id_ed25519.pub &lt;username&gt;@ela.cscs.ch</code></pre>
<p>Alternatively, you can copy the keys manually.</p>
<ol start=4 >
<li><p>Once your key is added to ela, manually connect to daint to authorize your key for the first time, while making sure you are logged-in in ela. Execute:</p>

</ol>
<pre><code class="sh hljs">[classXXX@ela2 ~]$ ssh daint</code></pre>
<p>This step shall prompt you to accept the daint server‚Äôs SSH key and enter the password you got from Moodle again.</p>
<ol start=5 >
<li><p>Edit your ssh config file located in <code>~/.ssh/config</code> and add following entries to it, making sure to replace <code>&lt;username&gt;</code> and key file with correct names, if needed:</p>

</ol>
<pre><code class="sh hljs">Host daint.alps
  HostName daint.alps.cscs.ch
  User &lt;username&gt;
  IdentityFile ~/.ssh/id_ed25519
  ProxyJump &lt;username&gt;@ela.cscs.ch
  AddKeysToAgent <span class=hljs-built_in >yes</span>
  ForwardAgent <span class=hljs-built_in >yes</span></code></pre>
<ol start=6 >
<li><p>Now you should be able to perform password-less login to daint as following</p>

</ol>
<pre><code class="sh hljs">ssh daint.alps</code></pre>
<blockquote>
<p>At this stage, you are logged into daint, but still on a login node and not a compute node.</p>
</blockquote>
<p>You can reach your home folder upon typing <code>cd &#36;HOME</code>, and your scratch space upon typing <code>cd &#36;SCRATCH</code>. Always make sure to run and save files from scratch folder.</p>
<div class=note ><div class=title >üí° Note</div>
<div class=messg ><p>To make things easier, you can create a soft link from your <code>&#36;HOME</code> pointing to <code>&#36;SCRATCH</code></p>
<pre><code class="sh hljs"><span class=hljs-built_in >ln</span> -s <span class=hljs-variable >$SCRATCH</span> scratch</code></pre></div></div>
<p>Make sure to remove any folders you may find in your scratch as those are the empty remaining from last year&#39;s course.</p>
<h3 id=setting_up_julia_on_alps ><a href="#setting_up_julia_on_alps" class=header-anchor >Setting up Julia on Alps</a></h3>
<p>The Julia setup on daint is handled by <a href="https://docs.cscs.ch/software/uenv/">uenv</a>, user environments that provide scientific applications, libraries and tools. The <a href="https://docs.cscs.ch/software/prgenv/julia/">Julia uenv</a> provides a fully configured environment to run Julia at Scales on Nvidia GPUs, using MPI as communication library. Julia is installed and managed by <a href="https://github.com/JuliaParallel/JUHPC">JUHPC</a> which wraps Juliaup and ensures it smoothly works on the supercomputer.</p>
<p><strong>Only the first time</strong> you will need to pull the Julia uenv on daint, and run Juliaup to install Julia.</p>
<ol>
<li><p>Open a terminal &#40;other than from within VS code&#41; and login to daint:</p>

</ol>
<pre><code class="sh hljs">ssh daint.alps</code></pre>
<ol start=2 >
<li><p>Download the Julia uenv image:</p>

</ol>
<pre><code class="sh hljs">uenv image pull julia/25.5:v1</code></pre>
<ol start=3 >
<li><p>Work-around a current limitations of Juliaup on Alps</p>

</ol>
<pre><code class="sh hljs"><span class=hljs-built_in >mkdir</span> <span class=hljs-variable >$SCRATCH</span>/tmp

<span class=hljs-built_in >export</span> TMPDIR=<span class=hljs-string >&quot;<span class=hljs-variable >$SCRATCH</span>/tmp&quot;</span></code></pre>
<ol start=4 >
<li><p>Once the download complete, start the uenv:</p>

</ol>
<pre><code class="sh hljs">uenv start --view=juliaup,modules julia/25.5:v1</code></pre>
<p>Adding a view &#40;<code>--view&#61;juliaup,modules</code>&#41; gives you explicit access to Juliaup and to modules.</p>
<ol start=5 >
<li><p>Only the first time, call into juliaup in order to install latest Julia</p>

</ol>
<pre><code class="sh hljs">juliaup</code></pre>
<p>At this point, you should be able to launch Julia by typing <code>julia</code> in the terminal.</p>
<div class=note ><div class=title >üí° Note</div>
<div class=messg >All Julia-related information can be found at <a href="https://docs.cscs.ch/software/prgenv/julia/">https://docs.cscs.ch/software/prgenv/julia/</a></div></div>
<h3 id=running_julia_interactively_on_alps ><a href="#running_julia_interactively_on_alps" class=header-anchor >Running Julia interactively on Alps</a></h3>
<p>Once the initial setup is completed, you can simply use Julia on daint by starting the Julia uenv, accessing a compute node &#40;using SLURM&#41;, and launching Julia to add CUDA.jl package:</p>
<div class=warning ><div class=title >‚ö†Ô∏è Warning&#33;</div>
<div class=messg >To perform any computation, you need to access a compute node using the SLURM scheduler.</div></div>
<ol>
<li><p>SSH into daint and start the Julia uenv</p>

</ol>
<pre><code class="sh hljs">ssh daint.alps

uenv start --view=juliaup,modules julia/25.5:v1</code></pre>
<ol start=2 >
<li><p>The next step is to secure an allocation using <code>salloc</code>, a functionality provided by the SLURM scheduler. Use <code>salloc</code> command to allocate one node &#40;<code>N1</code>&#41; on the GPU partition <code>-C&#39;gpu&#39;</code> on the project <code>class04</code> for 1 hour:</p>

</ol>
<pre><code class="sh hljs">salloc -C<span class=hljs-string >&#x27;gpu&#x27;</span> -Aclass04 -N1 --<span class=hljs-keyword >time</span>=01:00:00</code></pre>
<div class=note ><div class=title >üí° Note</div>
<div class=messg >You can check the status of the allocation typing <code>squeue --me</code>.</div></div>
<p>üëâ Running a <strong>remote job</strong> instead? <a href="#running_a_remote_job_on_alps">Jump right there</a></p>
<ol start=3 >
<li><p>Once you have your allocation &#40;<code>salloc</code>&#41; and the node, you can access the compute node by using the following <code>srun</code> command:</p>

</ol>
<pre><code class="sh hljs">srun -n1 --pty /bin/bash -l</code></pre>
<ol start=4 >
<li><p>Launch Julia in global or project environment</p>

</ol>
<pre><code class="sh hljs">julia</code></pre>
<ol start=5 >
<li><p>Within Julia, enter the package mode <code>&#93;</code>, check the status, and add <code>CUDA.jl</code> and <code>MPI.jl</code>:</p>

</ol>
<pre><code class="julia-repl hljs"><span class="hljs-meta prompt_">julia&gt;</span><span class=language-julia > ]
</span>
<span class=hljs-metap>(@v1.12) pkg&gt;</span> st

<span class=hljs-metap>(@v1.12) pkg&gt;</span> add CUDA, MPI</code></pre>
<ol start=6 >
<li><p>Then load CUDA and query version info</p>

</ol>
<pre><code class="julia-repl hljs"><span class="hljs-meta prompt_">julia&gt;</span><span class=language-julia > <span class=hljs-keyword >using</span> CUDA
</span>
<span class="hljs-meta prompt_">julia&gt;</span><span class=language-julia > CUDA.versioninfo()
</span>CUDA toolchain:
- runtime 12.8, local installation
- driver 550.54.15 for 13.0
- compiler 12.9

# [skipped lines]

Preferences:
- CUDA_Runtime_jll.version: 12.8
- CUDA_Runtime_jll.local: true

4 devices:
  0: NVIDIA GH200 120GB (sm_90, 93.953 GiB / 95.577 GiB available)
  1: NVIDIA GH200 120GB (sm_90, 93.951 GiB / 95.577 GiB available)
  2: NVIDIA GH200 120GB (sm_90, 93.955 GiB / 95.577 GiB available)
  3: NVIDIA GH200 120GB (sm_90, 93.954 GiB / 95.577 GiB available)</code></pre>
<ol start=7 >
<li><p>Try out your first calculation on the GH200 GPU</p>

</ol>
<pre><code class="julia-repl hljs"><span class="hljs-meta prompt_">julia&gt;</span><span class=language-julia > a = CUDA.ones(<span class=hljs-number >3</span>,<span class=hljs-number >4</span>);
</span>
<span class="hljs-meta prompt_">julia&gt;</span><span class=language-julia > b = CUDA.rand(<span class=hljs-number >3</span>,<span class=hljs-number >4</span>);
</span>
<span class="hljs-meta prompt_">julia&gt;</span><span class=language-julia > c = CUDA.zeros(<span class=hljs-number >3</span>,<span class=hljs-number >4</span>);
</span>
<span class="hljs-meta prompt_">julia&gt;</span><span class=language-julia > c .= a .+ b</span></code></pre>
<p>If you made it to here, you&#39;re most likely all set üöÄ</p>
<div class=warning ><div class=title >‚ö†Ô∏è Warning&#33;</div>
<div class=messg ><p>There is no interactive visualisation on daint. Make sure to produce <code>png</code> or <code>gifs</code>. Also to avoid plotting to fail, make sure to set the following <code>ENV&#91;&quot;GKSwstype&quot;&#93;&#61;&quot;nul&quot;</code> in the code. Also, it may be good practice to define the animation directory to avoid filling a <code>tmp</code>, such as</p>
<pre><code class="julia hljs"><span class=hljs-literal >ENV</span>[<span class=hljs-string >&quot;GKSwstype&quot;</span>]=<span class=hljs-string >&quot;nul&quot;</span>
<span class=hljs-keyword >if</span> isdir(<span class=hljs-string >&quot;viz_out&quot;</span>)==<span class=hljs-literal >false</span> mkdir(<span class=hljs-string >&quot;viz_out&quot;</span>) <span class=hljs-keyword >end</span>
loadpath = <span class=hljs-string >&quot;./viz_out/&quot;</span>; anim = Animation(loadpath,<span class=hljs-built_in >String</span>[])
println(<span class=hljs-string >&quot;Animation directory: <span class=hljs-subst >$(anim.dir)</span>&quot;</span>)</code></pre></div></div>
<h4 id=monitoring_gpu_usage ><a href="#monitoring_gpu_usage" class=header-anchor >Monitoring GPU usage</a></h4>
<p>You can use the <code>nvidia-smi</code> command to monitor GPU usage on a compute node on daint. Just type in the terminal or with Julia&#39;s REPL &#40;in shell mode&#41;.</p>
<h4 id=using_vs_code_on_alps ><a href="#using_vs_code_on_alps" class=header-anchor >Using VS code on Alps</a></h4>
<p>VS code support to remote connect to daint is getting better and better. If feeling adventurous, try out the <a href="https://docs.cscs.ch/access/vscode/">Connecting with VS Code</a> procedure. Any feedback welcome.</p>
<h3 id=running_a_remote_job_on_alps ><a href="#running_a_remote_job_on_alps" class=header-anchor >Running a remote job on Alps</a></h3>
<p>If you do not want to use an interactive session you can use the <code>sbatch</code> command to launch a job remotely on the machine. Example of a <code>submit.sh</code> you can launch &#40;without need of an allocation&#41; as <code>sbatch submit.sh</code>:</p>
<pre><code class="sh hljs"><span class=hljs-meta >#!/bin/bash -l</span>
<span class=hljs-comment >#SBATCH --account=class04</span>
<span class=hljs-comment >#SBATCH --job-name=&quot;my_gpu_run&quot;</span>
<span class=hljs-comment >#SBATCH --output=my_gpu_run.%j.o</span>
<span class=hljs-comment >#SBATCH --error=my_gpu_run.%j.e</span>
<span class=hljs-comment >#SBATCH --time=00:10:00</span>
<span class=hljs-comment >#SBATCH --nodes=1</span>
<span class=hljs-comment >#SBATCH --ntasks-per-node=1</span>
<span class=hljs-comment >#SBATCH --gpus-per-task=1</span>

srun --uenv julia/25.5:v1 --view=juliaup julia --project &lt;my_julia_gpu_script.jl&gt;</code></pre>
<div class=warning ><div class=title >‚ö†Ô∏è Warning&#33;</div>
<div class=messg >Make sure to have started the Julia uenv <strong>before</strong> executing the <code>sbatch</code> command or to include <code>--uenv julia/25.5:v1 --view&#61;juliaup</code> in the <code>srun</code> command.</div></div>
<h3 id=jupyterlab_access_on_alps ><a href="#jupyterlab_access_on_alps" class=header-anchor >JupyterLab access on Alps</a></h3>
<p>Some tasks and homework, are prepared as Jupyter notebook and can easily be executed within a JupyterLab environment. CSCS offers a convenient <a href="https://docs.cscs.ch/access/jupyterlab/#using-julia-in-jupyter">JupyterLab access</a>.</p>
<ol>
<li><p>First, create a soft link from your <code>&#36;HOME</code> pointing to <code>&#36;SCRATCH</code> &#40;do this on daint&#41;:</p>

</ol>
<pre><code class="sh hljs"><span class=hljs-built_in >ln</span> -s <span class=hljs-variable >$SCRATCH</span> scratch</code></pre>
<ol start=2 >
<li><p>Head to <a href="https://jupyter-daint.cscs.ch/">https://jupyter-daint.cscs.ch/</a>.</p>

<li><p>Login with your username and password you&#39;ve set for in the <a href="#account_setup">Account setup</a> step.</p>

<li><p>Follow the <a href="https://docs.cscs.ch/access/jupyterlab/#using-julia-in-jupyter">additional procedure to set up the Julia kernel in Jupyter</a>.</p>
<ul>
<li><p>In the <code>Advanced options</code>, provide as uenv <code>julia/25.5:v1</code> and <code>jupyter</code> as view.</p>

<li><p>Select the duration you want and <strong>Launch JupyterLab</strong>.</p>

<li><p><em>Only the first time</em> ‚Äì open the console from the JupyterLab launcher and run <code>install_ijulia</code></p>

</ul>

<li><p>From within JupyterLab, upload the notebook to work on and get started&#33;</p>

</ol>
<h3 id=transferring_files_on_alps ><a href="#transferring_files_on_alps" class=header-anchor >Transferring files on Alps</a></h3>
<p>Given that daint&#39;s <code>scratch</code> is not mounted on ela, it is unfortunately impossible to transfer files from/to daint using common sftp tools as they do not support the proxy-jump. Various solutions exist to workaround this, including manually handling transfers over terminal, using a tool which supports proxy-jump, or VS code.</p>
<p>To use VS code as development tool, make sure to have installed the <code>Remote-SSH</code> extension as described in the <a href="#vs_code_remote_-_ssh_setup">VS Code Remote - SSH setup</a> section. Then, in VS code Remote-SSH settings, make sure the <code>Remote Server Listen On Socket</code> is set to <code>true</code>.</p>
<p>The next step should work out of the box. You should be able to select <code>daint</code> from within the Remote Explorer side-pane. You should get logged into daint. You now can browse your files, change directory to, e.g., your scratch at <code>/capstor/scratch/cscs/&lt;username&gt;/</code>. Just drag and drop files in there to transfer them.</p>
<h3 id=julia_mpi_gpu_on_alps ><a href="#julia_mpi_gpu_on_alps" class=header-anchor >Julia MPI GPU on Alps</a></h3>
<p>The following step should allow you to run distributed memory parallelisation application on multiple GPU nodes on Alps.</p>
<ol>
<li><p>Make sure to have the Julia GPU environment loaded</p>

</ol>
<pre><code class="sh hljs">uenv start --view=juliaup,modules julia/25.5:v1</code></pre>
<ol start=2 >
<li><p>Then, you would need to allocate more than one node, let&#39;s say 2 nodes for 1 hours, using <code>salloc</code></p>

</ol>
<pre><code class="sh hljs">salloc -C<span class=hljs-string >&#x27;gpu&#x27;</span> -Aclass04 -N2 --<span class=hljs-keyword >time</span>=01:00:00</code></pre>
<ol start=3 >
<li><p>To launch a Julia &#40;GPU&#41; MPI script on 2 nodes &#40;and e.g. 8 GPUs&#41; using MPI, you can simply use <code>srun</code></p>

</ol>
<pre><code class="sh hljs">MPICH_GPU_SUPPORT_ENABLED=1 IGG_CUDAAWARE_MPI=1 JULIA_CUDA_USE_COMPAT=<span class=hljs-literal >false</span> srun -N2 -n8 --ntasks-per-node=4 --gpus-per-task=1 julia --project &lt;my_julia_mpi_script.jl&gt;</code></pre>
<p>If you do not want to use an interactive session you can use the <code>sbatch</code> command to launch an MPI job remotely on daint. Example of a <code>sbatch_mpi_daint.sh</code> you can launch &#40;without need of an allocation&#41; as <a href="https://github.com/eth-vaw-glaciology/course-101-0250-00/blob/main/scripts/l8_scripts/l8_sbatch_mpi_daint.sh"><code>sbatch sbatch_mpi_daint.sh</code></a>:</p>
<pre><code class="sh hljs"><span class=hljs-meta >#!/bin/bash -l</span>
<span class=hljs-comment >#SBATCH --account=class04</span>
<span class=hljs-comment >#SBATCH --job-name=&quot;diff2D&quot;</span>
<span class=hljs-comment >#SBATCH --output=diff2D.%j.o</span>
<span class=hljs-comment >#SBATCH --error=diff2D.%j.e</span>
<span class=hljs-comment >#SBATCH --time=00:05:00</span>
<span class=hljs-comment >#SBATCH --nodes=1</span>
<span class=hljs-comment >#SBATCH --ntasks-per-node=4</span>
<span class=hljs-comment >#SBATCH --gpus-per-task=1</span>

<span class=hljs-built_in >export</span> MPICH_GPU_SUPPORT_ENABLED=1
<span class=hljs-built_in >export</span> IGG_CUDAAWARE_MPI=1 <span class=hljs-comment ># IGG</span>
<span class=hljs-built_in >export</span> JULIA_CUDA_USE_COMPAT=<span class=hljs-literal >false</span> <span class=hljs-comment ># IGG</span>

srun --uenv julia/25.5:v1 --view=juliaup julia --project &lt;my_julia_mpi_gpu_script.jl&gt;</code></pre>
<div class=note ><div class=title >üí° Note</div>
<div class=messg >The scripts above can be found in the <a href="https://github.com/eth-vaw-glaciology/course-101-0250-00/blob/main/scripts/l8_scripts/">scripts</a> folder.</div></div>
<p>You may want to leverage CUDA-aware MPI, i.e., passing GPU pointers directly through the MPI-based update halo functions, then make sure to export the following <code>ENV</code> variables:</p>
<pre><code class="sh hljs"><span class=hljs-built_in >export</span> MPICH_RDMA_ENABLED_CUDA=1
<span class=hljs-built_in >export</span> IGG_CUDAAWARE_MPI=1</code></pre>
<div class=note ><div class=title >üí° Note</div>
<div class=messg >On daint, each MPI process &#40;SLURM task&#41; sees a single GPU with <code>ID &#61; 0</code> as we request <code>--gpus-per-task&#61;1</code>. This implies that there is no need to rely on other mechanisms such as using shared memory MPI communicator to convert global to local MPI ranks for GPU selection &#40;<a href="https://docs.cscs.ch/running/slurm/#one-rank-per-gpu">more about this the in CSCS doc</a>&#41;.</div></div>
<div class=warning ><div class=title >‚ö†Ô∏è Warning&#33;</div>
<div class=messg ><p>Using ImplicitGlobalGrid.jl on daint, one needs to ensure to set <code>select_device &#61; false</code> in the <code>init_global_grid</code> kwarg:</p>
<pre><code class="julia hljs">init_global_grid(...; select_device = <span class=hljs-literal >false</span>)</code></pre></div></div>
<h3 id=profiling_on_alps ><a href="#profiling_on_alps" class=header-anchor >Profiling on Alps</a></h3>
<p>Profiling using the <a href="https://docs.cscs.ch/software/devtools/nvidia-nsight/">NVIDIA Nsight Systems</a> is available with any uenv that comes with a CUDA compiler, including the Julia uenv. As a sampling profiler, it can be used to profile applications written in Julia by wrapping the application with the Nsight Systems profiler executable.</p>
<p>The profiler is triggered by using the <code>nsys profile</code> command, available upon loading the CUDA module. On daint prepare the working environment as following</p>
<pre><code class="sh hljs">uenv start --view=juliaup,modules julia/25.5:v1

ml cuda</code></pre>
<p>Then, for example, request an allocation for 2 nodes in order to have access to 8 GH200 GPUs:</p>
<pre><code class="sh hljs">salloc -C<span class=hljs-string >&#x27;gpu&#x27;</span> -Aclass04 -N2 --<span class=hljs-keyword >time</span>=01:00:00</code></pre>
<p>To then profile an application &#40;e.g. the <a href="https://github.com/eth-vaw-glaciology/course-101-0250-00/blob/main/scripts/l10_diff_3d_hidecomm.jl">3D diffusion code</a>&#41;, launch <code>srun</code> with the following parameters:</p>
<pre><code class="sh hljs">MPICH_GPU_SUPPORT_ENABLED=1 IGG_CUDAAWARE_MPI=1 JULIA_CUDA_USE_COMPAT=<span class=hljs-literal >false</span> srun -N2 -n8 --ntasks-per-node=4 --gpus-per-task=1 \
nsys profile --force-overwrite=<span class=hljs-literal >true</span> --start-later=<span class=hljs-literal >true</span> --capture-range=cudaProfilerApi --capture-range-end=stop -t nvtx,cuda,mpi --mpi-impl=mpich -o prof_hidecomm.%q{SLURM_PROCID}.%q{SLURM_JOBID} \
julia --project diff_3d_hidecomm.jl</code></pre>
<p>This will launch the code on 2 nodes, 8 GPUs &#40;4 tasks per node&#41;. <code>srun</code> will call into <code>nsys profile</code> to profile a specific portion of the code and report NVTX, CUDA and MPI traces for the MPICH MPI implementation. The produced output files are named after each global MPI rank. This procedure wraps the <code>julia --project</code> call by the profiler.</p>
<p>The produced output files &#40;<code>.nsys-rep</code> extension&#41; can be analysed using the <a href="https://developer.nvidia.com/nsight-systems">NVIDIA Nsight Systems GUI application</a> that you can download from NVIDIA website and run locally.</p>
<div class=page-foot >
  <div class=copyright >
    <a href="https://github.com/eth-vaw-glaciology/course-101-0250-00/"><b>Edit this page on <img class=github-logo  src="https://unpkg.com/ionicons@5.1.2/dist/svg/logo-github.svg"></b></a><br>
    Last modified: November 19, 2025. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
  </div>
</div>
</div>
    </div>