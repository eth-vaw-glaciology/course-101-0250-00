<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/course-101-0250-00/libs/katex/katex.min.css"> <link rel=stylesheet  href="/course-101-0250-00/libs/highlight/github.min.css"> <link rel=stylesheet  href="/course-101-0250-00/css/franklin.css"> <link rel=stylesheet  href="/course-101-0250-00/css/poole_hyde.css"> <link rel=stylesheet  href="/course-101-0250-00/css/custom.css"> <style> html {font-size: 17px;} .franklin-content {position: relative; padding-left: 8%; padding-right: 5%; line-height: 1.35em;} @media (min-width: 940px) { .franklin-content {width: 100%; margin-left: auto; margin-right: auto;} } @media (max-width: 768px) { .franklin-content {padding-left: 6%; padding-right: 6%;} } </style> <link rel=icon  href="/course-101-0250-00/assets/favicon.png"> <title>Lecture 6</title> <style> .content {max-width: 50rem} </style> <div class=sidebar > <div class="container sidebar-sticky"> <div class=sidebar-about > <img src="/course-101-0250-00/assets/vaw_logo.png" style="width: 180px; height: auto; display: inline"> <div style="font-weight: margin-bottom: 0.5em"><a href="/course-101-0250-00/"> Fall 2021</a> <span style="opacity: 0.7;">| <a href="http://www.vvz.ethz.ch/Vorlesungsverzeichnis/lerneinheit.view?semkez=2021W&ansicht=KATALOGDATEN&lerneinheitId=155538&lang=en"> ETHZ 101-0250-00</a></span></div> <br> <h1><a href="/course-101-0250-00/">Solving partial differential equations in parallel on GPUs</a></h1> <div style="line-height:18px; font-size: 15px; opacity: 0.85">by <a href="https://vaw.ethz.ch/en/people/person-detail.MjcwOTYw.TGlzdC8xOTYxLDE1MTczNjI1ODA=.html">Ludovic Räss</a>, <a href="https://vaw.ethz.ch/en/personen/person-detail.html?persid=124402">Mauro Werder</a> & <a href="https://www.cscs.ch/about/staff/">Samuel Omlin</a> </div> </div> <br> <style> </style> <nav class=sidebar-nav  style="opacity: 0.9"> <a class="sidebar-nav-item " href="/course-101-0250-00/"><b>Welcome</b></a> <a class="sidebar-nav-item " href="/course-101-0250-00/logistics/">Logistics</a> <a class="sidebar-nav-item " href="/course-101-0250-00/homework/">Homework</a> <a class="sidebar-nav-item " href="/course-101-0250-00/software_install/">Software install</a> <a class="sidebar-nav-item " href="/course-101-0250-00/extras/">Extras</a> <br> <div class=course-section >Part 1 - Introduction</div> <a class="sidebar-nav-item " href="/course-101-0250-00/lecture1/">Lecture 1</a> <a class="sidebar-nav-item " href="/course-101-0250-00/lecture2/">Lecture 2</a> <a class="sidebar-nav-item " href="/course-101-0250-00/lecture3/">Lecture 3</a> <a class="sidebar-nav-item " href="/course-101-0250-00/lecture4/">Lecture 4</a> <div class=course-section >Part 2 - Solving PDEs on GPUs</div> <a class="sidebar-nav-item " href="/course-101-0250-00/lecture5/">Lecture 5</a> <a class="sidebar-nav-item active" href="/course-101-0250-00/lecture6/">Lecture 6</a> <div class=course-section >Part 3 - Projects</div> </nav> </div> </div> <div class="content container"> <div class=franklin-content > <h1 id=lecture_6 ><a href="#lecture_6" class=header-anchor >Lecture 6</a></h1> <blockquote> <p><strong>Agenda</strong><br />📚 GPU computing &amp; performance assessment &#40;continued&#41;<br />💻 Unit testing and continuous integration &#40;CI&#41;<br />🚧 Exercises:</p> <ul> <li><p>Data transfer optimisations on GPUs</p> <li><p>GPU codes for diffusion and acoustic waves</p> <li><p>Deploy GitHub CI</p> </ul> </blockquote> <p><hr /> </p> <p><a id=content  class=anchor ></a> <strong>Content</strong></p> <div class=franklin-toc ><ol><li><a href="#lecture_6">Lecture 6</a><li><a href="#gpu_computing_and_performance_assessment">GPU computing and performance assessment</a><ol><li><a href="#scientific_applications_performance">Scientific applications&#39; performance</a><li><a href="#gpu_array_programming">GPU array programming</a><li><a href="#gpu_kernel_programming">GPU kernel programming</a></ol><li><a href="#gpu_computing_and_kernel_programming">GPU computing and kernel programming</a><li><a href="#exercises_-_lecture_6">Exercises - lecture 6</a><ol><li><a href="#excercise_1_-_data_transfer_optimisations">Excercise 1 - <strong>Data transfer optimisations</strong></a></ol></ol></div> <p><a href="#exercises_-_lecture_6"><em>👉 get started with exercises</em></a></p> <hr /> <h1 id=gpu_computing_and_performance_assessment ><a href="#gpu_computing_and_performance_assessment" class=header-anchor >GPU computing and performance assessment</a></h1> <h3 id=the_goal_of_this_lecture_6_is_to ><a href="#the_goal_of_this_lecture_6_is_to" class=header-anchor >The goal of this lecture 6 is to:</a></h3> <ol> <li><p>Learn about</p> </ol> <ul> <li><p>how to establish the peak memory throughput of your GPU</p> <li><p>GPU array and kernel programming</p> </ul> <ol start=2 > <li><p>Consolidate</p> </ol> <ul> <li><p>the basics of benchmarking</p> <li><p>how to compute achieved memory throughput</p> </ul> <p>In order to get started, we need to connect to a machine which has GPU&#40;s&#41;.</p> <p>Let&#39;s take a few minutes to get started.</p> <p>Head to:</p> <ul> <li><p><a href="/course-101-0250-00/software_install/#accessing_the_gpu_resources_on_octopus">Software insatall</a> for the directions and,</p> <li><p><a href="https://moodle-app2.let.ethz.ch/course/view.php?id&#61;15755#section-0">Moodle</a> for some secret infos.</p> </ul> <p>Replace all XX in this lecture, and add final text for ix, iy indices...</p> <div class=note ><div class=title >💡 Note</div> <div class=messg >Values reported in this notebook are for the Nvidia P100 16GB PCIe GPU. You are running on Nvidia Tesla V100 32GB SXM2. Comparing the values you get - it may show that one cannot expect a fine tuned strategy to work always 100&#37; well on future &#40;or past&#41; architectures.</div></div> <p>We will use the packages <code>CUDA</code>, <code>BenchmarkTools</code> and <code>Plots</code> to create a little performance laboratory:</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> CUDA
<span class=hljs-keyword >using</span> BenchmarkTools</code></pre> <h2 id=scientific_applications_performance ><a href="#scientific_applications_performance" class=header-anchor >Scientific applications&#39; performance</a></h2> <p>The performance of most scientific applications nowadays is bound by memory access speed &#40;<em>memory-bound</em>&#41; rather than by the speed computations can be done &#40;<em>compute-bound</em>&#41;.</p> <p>The reason is that current GPUs &#40;and CPUs&#41; can do many more computations in a given amount of time than they can access numbers from main memory.</p> <p>This imbalance can be quantified by dividing the computation peak performance &#91;GFLOP/s&#93; by the memory access peak performance &#91;GB/s&#93; and multiplied by the size of a number in Bytes &#40;for simplicity, theoretical peak performance values as specified by the vendors can be used&#41;. For example for the Tesla P100 GPU, it is:</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mfrac><mrow><mn>5300</mn><mtext> </mtext><mrow><mo stretchy=false >[</mo><mi mathvariant=normal >G</mi><mi mathvariant=normal >F</mi><mi mathvariant=normal >l</mi><mi mathvariant=normal >o</mi><mi mathvariant=normal >p</mi><mi mathvariant=normal >/</mi><mi mathvariant=normal >s</mi><mo stretchy=false >]</mo></mrow></mrow><mrow><mn>732</mn><mtext> </mtext><mrow><mo stretchy=false >[</mo><mi mathvariant=normal >G</mi><mi mathvariant=normal >B</mi><mi mathvariant=normal >/</mi><mi mathvariant=normal >s</mi><mo stretchy=false >]</mo></mrow></mrow></mfrac><mtext> </mtext><mo>×</mo><mtext> </mtext><mn>8</mn><mo>=</mo><mn>58</mn></mrow><annotation encoding="application/x-tex"> \frac{5300 ~\mathrm{[GFlop/s]}}{732 ~\mathrm{[GB/s]}}~×~8 = 58 </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:2.363em;vertical-align:-0.936em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.427em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >7</span><span class=mord >3</span><span class=mord >2</span><span class="mspace nobreak"> </span><span class=mord ><span class=mopen >[</span><span class="mord mathrm">G</span><span class="mord mathrm">B</span><span class="mord mathrm">/</span><span class="mord mathrm">s</span><span class=mclose >]</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >5</span><span class=mord >3</span><span class=mord >0</span><span class=mord >0</span><span class="mspace nobreak"> </span><span class=mord ><span class=mopen >[</span><span class="mord mathrm">G</span><span class="mord mathrm">F</span><span class="mord mathrm">l</span><span class="mord mathrm">o</span><span class="mord mathrm">p</span><span class="mord mathrm">/</span><span class="mord mathrm">s</span><span class=mclose >]</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace nobreak"> </span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >×</span><span class="mspace nobreak"> </span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mord >8</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >5</span><span class=mord >8</span></span></span></span></span> <p>&#40;here computed with double precision values taken from <a href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-p100/pdf/nvidia-tesla-p100-PCIe-datasheet.pdf">the vendor&#39;s product specification sheet</a>&#41;</p> <p>So we can do 58 floating point operations per number read from main memory or written to it.</p> <p>As a consequence, we can consider <strong>floating point operations be &quot;for free&quot;</strong> when we work in the memory-bounded regime as in this lecture.</p> <p>Therefore, let us start with investigating the performance of different ways to express and launch GPU memory copies. We will wrap all of these memory copies in functions, to enable the Julia compiler to optimize them best.</p> <p>There exists already the function <code>copyto&#33;</code>, which permits to copy data from one pre-allocated array to another; thus, we start with analysing this function&#39;s performance.</p> <p>But first, let us list what GPUs are available and make sure we assign no more than one user per GPU:</p> <pre><code class="julia hljs">collect(devices())
device!(<span class=hljs-number >0</span>) <span class=hljs-comment ># select a GPU between 0-7</span></code></pre> <p>To this purpose, we allocate two arrays and benchmark the function using <code>BenchmarkTools</code>:</p> <pre><code class="julia hljs">nx = ny = <span class=hljs-number >32</span>
A = CUDA.zeros(<span class=hljs-built_in >Float64</span>, nx, ny);
B = CUDA.rand(<span class=hljs-built_in >Float64</span>, nx, ny);
<span class=hljs-meta >@benchmark</span> <span class=hljs-keyword >begin</span> copyto!($A, $B); synchronize() <span class=hljs-keyword >end</span></code></pre> <div class=note ><div class=title >💡 Note</div> <div class=messg >Previously defined variables are interpolated with <code>&#36;</code> into the benchmarked expression.</div></div> <div class=warning ><div class=title >⚠️ Warning&#33;</div> <div class=messg >If not specified otherwise, <code>CUDA.zeros&#40;nx, ny&#41;</code> allocates <code>Float32</code>.</div></div> <p>Time samples resulting from benchmarking as just performed follow normally a right skewed distribution.</p> <p>For such distribution, the median is the most robust of the commonly used estimators of the central tendency; the minimum is in general also a good estimator as hardware cannot by accident run faster than with the ideal and it is as a result commonly used for reporting performance &#40;for more information on estimators see <a href="https://juliaci.github.io/BenchmarkTools.jl/stable/manual/#Which-estimator-should-I-use?">here</a>&#41;.</p> <p>Using <code>@belapsed</code> instead of <code>@benchmark</code>, we directly obtain the minimum of the taken time samples:</p> <pre><code class="julia hljs">t_it = <span class=hljs-meta >@belapsed</span> <span class=hljs-keyword >begin</span> copyto!($A, $B); synchronize() <span class=hljs-keyword >end</span></code></pre>
<p>Now, we know that it does not take &quot;an awful lot of time&quot;. Of course, we do not want to stop here, but figure out how good the achieved performance was.</p>
<p>To this aim, we compute the <em>total memory throughput</em>, <code>T_tot</code> &#91;GB/s&#93;, which is defined as the volume of the copied data &#91;GB&#93; divided by the time spent &#91;s&#93;:</p>
<pre><code class="julia hljs">T_tot = <span class=hljs-number >2</span>*<span class=hljs-number >1</span>/<span class=hljs-number >1e9</span>*nx*ny*sizeof(<span class=hljs-built_in >Float64</span>)/t_it</code></pre>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >The factor <code>2</code> comes from the fact that the data is read and written &#40;<code>2</code> operations&#41;.</div></div>
<p>Compare now <code>T_tot</code> with the known peak memory throughput, <code>T_peak</code>, which is found e.g. in scientific or vendor publications &#40;for the Nvidia Tesla P100 GPUs, it is 559 GB/s, according to <a href="https://doi.org/10.1109/P3HPC51967.2020.00006">this source</a>, for the Nvidia Tesla V100 GPUs, it is 837 GB/s&#41;.</p>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >Achievable peak memory throughput is usually significantly lower than the <em>theoretical peak bandwidth</em> announced by the vendor &#40;for the <a href="https://images.nvidia.com/content/technologies/volta/pdf/437317-Volta-V100-DS-NV-US-WEB.pdf">Tesla V100 GPUs</a>, the latter is 900 GB/s as noted already earlier&#41;.</div></div>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >Here 1 GB is 1e9 Bytes as in the publication, where the peak memory throughput of the Tesla P100 GPU was obtained from.</div></div>
<p>You have surely found <code>T_tot</code> to be orders of magnitude below <code>T_peak</code>. This is to be expected when copying a small array.</p>
<p>Let us determine how <code>T_tot</code> behaves with increasing array sizes:</p>
<pre><code class="julia hljs">array_sizes = []
throughputs = []
<span class=hljs-keyword >for</span> pow = <span class=hljs-number >0</span>:<span class=hljs-number >11</span>
    nx = ny = <span class=hljs-number >32</span>*<span class=hljs-number >2</span>^pow
    <span class=hljs-keyword >if</span> (<span class=hljs-number >3</span>*nx*ny*sizeof(<span class=hljs-built_in >Float64</span>) &gt; CUDA.available_memory()) <span class=hljs-keyword >break</span>; <span class=hljs-keyword >end</span>
    A = CUDA.zeros(<span class=hljs-built_in >Float64</span>, nx, ny);
    B = CUDA.rand(<span class=hljs-built_in >Float64</span>, nx, ny);
    t_it = <span class=hljs-meta >@belapsed</span> <span class=hljs-keyword >begin</span> copyto!($A, $B); synchronize() <span class=hljs-keyword >end</span>
    T_tot = <span class=hljs-number >2</span>*<span class=hljs-number >1</span>/<span class=hljs-number >1e9</span>*nx*ny*sizeof(<span class=hljs-built_in >Float64</span>)/t_it
    push!(array_sizes, nx)
    push!(throughputs, T_tot)
    println(<span class=hljs-string >&quot;(nx=ny=<span class=hljs-variable >$nx</span>) T_tot = <span class=hljs-subst >$(T_tot)</span>&quot;</span>)
    CUDA.unsafe_free!(A)
    CUDA.unsafe_free!(B)
<span class=hljs-keyword >end</span></code></pre>
<p>You can observe that the best performance is on pair with <code>T_peak</code> or a bit lower &#40;measured 522 GB/s with the Tesla P100 GPU&#41; as <code>copyto&#33;</code> is a function that needs to work in all possible cases and it is not specifically optimised for a particular hardware.</p>
<p>Furthermore, we note that best performance is obtained for large arrays &#40;in the order of Gigabytes&#41;.</p>
<p>We will use the array size for which we obtained the best result for the remainder of the performance experiments:</p>
<pre><code class="julia hljs">T_tot_max, index = findmax(throughputs)
nx = ny = array_sizes[index]
A = CUDA.zeros(<span class=hljs-built_in >Float64</span>, nx, ny);
B = CUDA.rand(<span class=hljs-built_in >Float64</span>, nx, ny);</code></pre>
<h2 id=gpu_array_programming ><a href="#gpu_array_programming" class=header-anchor >GPU array programming</a></h2>
<p>Let us now create our own memory copy function using GPU <em>Array Programming</em> &#40;AP&#41;.</p>
<p>We can write a memory copy simply as <code>A .&#61; B</code>; and wrap it in a function using Julia&#39;s concise notation, it looks as follows:</p>
<pre><code class="julia hljs"><span class=hljs-meta >@inbounds</span> memcopy_AP!(A, B) = (A .= B)</code></pre>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >We use <code>@inbounds</code> macro to make sure no array bounds checking is performed, which would slow down significantly. Note, furthermore, that outside of these exercises it can be more convenient not to use the <code>@inbounds</code> macro, but to deactivate bounds checking instead globally for high performance runs by calling julia as follows : <code>julia --check-bounds&#61;no ...</code></div></div>
<div class=note ><div class=title >💡 Note</div>
<div class=messg ><code>A &#61; B</code> would not do a memcopy, but make <code>A</code> an alias of <code>B</code>, i.e. make <code>A</code> point to the same data in memory as <code>B</code>.</div></div>
<p>We also benchmark it and compute <code>T_tot</code>:</p>
<pre><code class="julia hljs">t_it = <span class=hljs-meta >@belapsed</span> <span class=hljs-keyword >begin</span> memcopy_AP!($A, $B); synchronize() <span class=hljs-keyword >end</span>
T_tot = <span class=hljs-number >2</span>*<span class=hljs-number >1</span>/<span class=hljs-number >1e9</span>*nx*ny*sizeof(<span class=hljs-built_in >Float64</span>)/t_it</code></pre>
<p>The performance you observe might be a little lower than with the <code>copyto&#33;</code> function &#40;measured 496 GB/s with the Tesla P100 GPU&#41;.</p>
<p>The few experiments that we have done together so far have shown you already that performing memory copy with maximal possible performance &#40;T_peak&#41; is not a completely trivial task.</p>
<h2 id=gpu_kernel_programming ><a href="#gpu_kernel_programming" class=header-anchor >GPU kernel programming</a></h2>
<p>We will now use GPU <em>Kernel Programming</em> &#40;KP&#41; to try to get closer to <code>T_peak</code>.</p>
<p>A memory copy kernel can be written e.g. as follows:</p>
<pre><code class="julia hljs"><span class=hljs-meta >@inbounds</span> <span class=hljs-keyword >function</span> memcopy_KP!(A, B)
    ix = (blockIdx().x-<span class=hljs-number >1</span>) * blockDim().x + threadIdx().x
    iy = (blockIdx().y-<span class=hljs-number >1</span>) * blockDim().y + threadIdx().y
    A[ix,iy] = B[ix,iy]
    <span class=hljs-keyword >return</span> <span class=hljs-literal >nothing</span>
<span class=hljs-keyword >end</span></code></pre>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >Indices <code>ix</code> and <code>iy</code> replace the loop indices providing a &quot;vectorised&quot; map of threads - the core to leverage GPU performance. We&#39;ll come back to this in a second part of this lecture.</div></div>
<p>Then, in order to copy the &#40;entire&#41; array <code>B</code> to <code>A</code>, we need to launch the kernel such that the above indices <code>ix</code> and <code>iy</code> map exactly to each array cell.</p>
<p>Therefore, we need to have <code>blocks&#91;1&#93;*threads&#91;1&#93; &#61;&#61; nx</code> and <code>blocks&#91;2&#93;*threads&#91;2&#93; &#61;&#61; ny</code>.</p>
<p>We will try first with the simplest possible option using only one thread per block:</p>
<pre><code class="julia hljs">threads = (<span class=hljs-number >1</span>, <span class=hljs-number >1</span>)
blocks  = (nx, ny)
t_it = <span class=hljs-meta >@belapsed</span> <span class=hljs-keyword >begin</span> <span class=hljs-meta >@cuda</span> blocks=$blocks threads=$threads memcopy_KP!($A, $B); synchronize() <span class=hljs-keyword >end</span>
T_tot = <span class=hljs-number >2</span>*<span class=hljs-number >1</span>/<span class=hljs-number >1e9</span>*nx*ny*sizeof(<span class=hljs-built_in >Float64</span>)/t_it</code></pre>
<p><code>T_tot</code> is certainly orders of magnitude below <code>T_peak</code> with this kernel launch parameters.</p>
<p>We need to take into account that single threads cannot run completely independently, but threads are launched in small groups within a block, called <em>warps</em>; a warp consists of 32 threads on current GPUs.</p>
<p>Furthermore, warps should access contiguous memory for best performance.</p>
<p>We therefore retry using 32 threads &#40;one warp&#41; per block as follows:</p>
<pre><code class="julia hljs">threads = (<span class=hljs-number >32</span>, <span class=hljs-number >1</span>)
blocks  = (nx÷threads[<span class=hljs-number >1</span>], ny)
t_it = <span class=hljs-meta >@belapsed</span> <span class=hljs-keyword >begin</span> <span class=hljs-meta >@cuda</span> blocks=$blocks threads=$threads memcopy_KP!($A, $B); synchronize() <span class=hljs-keyword >end</span>
T_tot = <span class=hljs-number >2</span>*<span class=hljs-number >1</span>/<span class=hljs-number >1e9</span>*nx*ny*sizeof(<span class=hljs-built_in >Float64</span>)/t_it</code></pre>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >For simplicity, the number of threads was set here explicitly to 32; more future proof would be to retrieve the warp size from the corresponding CUDA attribute by doing: <code>attribute&#40;device&#40;&#41;,CUDA.DEVICE_ATTRIBUTE_WARP_SIZE&#41;</code>.</div></div>
<p><code>T_tot</code> is now probably in the order of magnitude of <code>T_peak</code>, yet depending on the used GPU it can be still significantly below &#40;measured 302 GB/s with the Tesla P100 GPU&#41;.</p>
<p>If <code>T_tot</code> is significantly below <code>T_peak</code>, then we need to set the numbers of threads per block closer to the maximum the GPU allows.</p>
<p>Let us determine how <code>T_tot</code> behaves with an increasing number of threads per blocks:</p>
<pre><code class="julia hljs">max_threads  = attribute(device(),CUDA.DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK)
thread_count = []
throughputs  = []
<span class=hljs-keyword >for</span> pow = <span class=hljs-built_in >Int</span>(log2(<span class=hljs-number >32</span>)):<span class=hljs-built_in >Int</span>(log2(max_threads))
    threads = (<span class=hljs-number >2</span>^pow, <span class=hljs-number >1</span>)
    blocks  = (nx÷threads[<span class=hljs-number >1</span>], ny)
    t_it = <span class=hljs-meta >@belapsed</span> <span class=hljs-keyword >begin</span> <span class=hljs-meta >@cuda</span> blocks=$blocks threads=$threads memcopy_KP!($A, $B); synchronize() <span class=hljs-keyword >end</span>
    T_tot = <span class=hljs-number >2</span>*<span class=hljs-number >1</span>/<span class=hljs-number >1e9</span>*nx*ny*sizeof(<span class=hljs-built_in >Float64</span>)/t_it
    push!(thread_count, prod(threads))
    push!(throughputs, T_tot)
    println(<span class=hljs-string >&quot;(threads=<span class=hljs-variable >$threads</span>) T_tot = <span class=hljs-subst >$(T_tot)</span>&quot;</span>)
<span class=hljs-keyword >end</span></code></pre>
<p>You should observe now that beyond a certain minimum number of threads per block &#40;64 with the Tesla P100 GPU&#41;, <code>T_tot</code> is quite close to <code>T_peak</code> &#40;which exact thread/block configuration leads to the best <code>T_tot</code> depends on the used GPU architecture&#41;.</p>
<p>Instead of increasing the number of threads only in the x dimension, we can also do so in the y dimension.</p>
<p>We keep though 32 threads in the x dimension in order to let the warps access contiguous memory:</p>
<pre><code class="julia hljs">thread_count = []
throughputs  = []
<span class=hljs-keyword >for</span> pow = <span class=hljs-number >0</span>:<span class=hljs-built_in >Int</span>(log2(max_threads/<span class=hljs-number >32</span>))
    threads = (<span class=hljs-number >32</span>, <span class=hljs-number >2</span>^pow)
    blocks  = (nx÷threads[<span class=hljs-number >1</span>], ny÷threads[<span class=hljs-number >2</span>])
    t_it = <span class=hljs-meta >@belapsed</span> <span class=hljs-keyword >begin</span> <span class=hljs-meta >@cuda</span> blocks=$blocks threads=$threads memcopy_KP!($A, $B); synchronize() <span class=hljs-keyword >end</span>
    T_tot = <span class=hljs-number >2</span>*<span class=hljs-number >1</span>/<span class=hljs-number >1e9</span>*nx*ny*sizeof(<span class=hljs-built_in >Float64</span>)/t_it
    push!(thread_count, prod(threads))
    push!(throughputs, T_tot)
    println(<span class=hljs-string >&quot;(threads=<span class=hljs-variable >$threads</span>) T_tot = <span class=hljs-subst >$(T_tot)</span>&quot;</span>)
<span class=hljs-keyword >end</span></code></pre>
<p><code>T_tot</code> is even slightly better in general. Much more important is though that a thread block accesses now not a 1D-line of the arrays, but a 2D block.</p>
<p>We will see later that this is of great benefit when, e.g., computing finite difference derivatives in x and y direction.</p>
<p>So far, we experimented with memory copy in the strict sense: copy an array from one place to the other. When doing computations, we often read more data than we write.</p>
<p>We will therefore also do a few experiments on another commonly benchmarked case: read two arrays and write only one.</p>
<p>We modify therefore the previous kernel to take a third array <code>C</code> as input and add it to <code>B</code> &#40;the rest is identical&#41;:</p>
<pre><code class="julia hljs"><span class=hljs-meta >@inbounds</span> <span class=hljs-keyword >function</span> memcopy2_KP!(A, B, C)
    ix = (blockIdx().x-<span class=hljs-number >1</span>) * blockDim().x + threadIdx().x
    iy = (blockIdx().y-<span class=hljs-number >1</span>) * blockDim().y + threadIdx().y
    A[ix,iy] = B[ix,iy] + C[ix,iy]
    <span class=hljs-keyword >return</span> <span class=hljs-literal >nothing</span>
<span class=hljs-keyword >end</span></code></pre>
<p>Then, we test exactly as for the previous kernel how <code>T_tot</code> behaves with an increasing number of threads per blocks in y dimension, keeping it fixed to 32 in x dimension:</p>
<pre><code class="julia hljs">C = CUDA.rand(<span class=hljs-built_in >Float64</span>, nx, ny);
thread_count = []
throughputs  = []
<span class=hljs-keyword >for</span> pow = <span class=hljs-number >0</span>:<span class=hljs-built_in >Int</span>(log2(max_threads/<span class=hljs-number >32</span>))
    threads = (<span class=hljs-number >32</span>, <span class=hljs-number >2</span>^pow)
    blocks  = (nx÷threads[<span class=hljs-number >1</span>], ny÷threads[<span class=hljs-number >2</span>])
    t_it = <span class=hljs-meta >@belapsed</span> <span class=hljs-keyword >begin</span> <span class=hljs-meta >@cuda</span> blocks=$blocks threads=$threads memcopy2_KP!($A, $B, $C); synchronize() <span class=hljs-keyword >end</span>
    T_tot = <span class=hljs-number >3</span>*<span class=hljs-number >1</span>/<span class=hljs-number >1e9</span>*nx*ny*sizeof(<span class=hljs-built_in >Float64</span>)/t_it
    push!(thread_count, prod(threads))
    push!(throughputs, T_tot)
    println(<span class=hljs-string >&quot;(threads=<span class=hljs-variable >$threads</span>) T_tot = <span class=hljs-subst >$(T_tot)</span>&quot;</span>)
<span class=hljs-keyword >end</span></code></pre>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >There is now a factor <code>3</code> instead of <code>2</code> in the computation of <code>T_tot</code>: <code>2</code> arrays are read and <code>1</code> written &#40;<code>3</code> operations&#41;.</div></div>
<p>Compare now the best measured <code>T_tot</code> to the <code>T_peak</code> obtained from the publication and if it is higher, then it means we need to correct <code>T_peak</code> to take the value of the <code>T_tot</code> measured &#40;<code>T_tot</code> measured with the Tesla P100 GPU is 561 GB/s, i.e., 2 GB/s higher than the <code>T_peak</code> obtained from the publication mentioned earlier&#41;.</p>
<p>Note that the <code>T_peak</code> reported in the publication was obtained with a slightly different kernel which multiplies C with a scalar in addition; it is usually referred to as <em>triad</em>.</p>
<p>For completeness, we will also quickly benchmark a <em>triad</em> kernel.</p>
<p>To this purpose, we will directly use the best thread/block configuration that we have found in the previous experiment:</p>
<pre><code class="julia hljs"><span class=hljs-meta >@inbounds</span> <span class=hljs-keyword >function</span> memcopy_triad_KP!(A, B, C, s)
    ix = (blockIdx().x-<span class=hljs-number >1</span>) * blockDim().x + threadIdx().x
    iy = (blockIdx().y-<span class=hljs-number >1</span>) * blockDim().y + threadIdx().y
    A[ix,iy] = B[ix,iy] + s*C[ix,iy]
    <span class=hljs-keyword >return</span> <span class=hljs-literal >nothing</span>
<span class=hljs-keyword >end</span>

s = rand()

T_tot_max, index = findmax(throughputs)
threads = (<span class=hljs-number >32</span>, thread_count[index]÷<span class=hljs-number >32</span>)
blocks  = (nx÷threads[<span class=hljs-number >1</span>], ny÷threads[<span class=hljs-number >2</span>])
t_it = <span class=hljs-meta >@belapsed</span> <span class=hljs-keyword >begin</span> <span class=hljs-meta >@cuda</span> blocks=$blocks threads=$threads memcopy_triad_KP!($A, $B, $C, $s); synchronize() <span class=hljs-keyword >end</span>
T_tot = <span class=hljs-number >3</span>*<span class=hljs-number >1</span>/<span class=hljs-number >1e9</span>*nx*ny*sizeof(<span class=hljs-built_in >Float64</span>)/t_it</code></pre>
<p>There should be no significant difference between <code>T_tot</code> of this triad kernel and of the previous kernel &#40;with the Tesla P100 GPU, it is 561 GB/s with both kernels&#41;.</p>
<p>Finally, let us also check the triad performance we obtain with GPU array programming:</p>
<pre><code class="julia hljs"><span class=hljs-meta >@inbounds</span> memcopy_triad_AP!(A, B, C, s) = (A .= B.+ s.*C)

t_it = <span class=hljs-meta >@belapsed</span> <span class=hljs-keyword >begin</span> memcopy_triad_AP!($A, $B, $C, $s); synchronize() <span class=hljs-keyword >end</span>
T_tot = <span class=hljs-number >3</span>*<span class=hljs-number >1</span>/<span class=hljs-number >1e9</span>*nx*ny*sizeof(<span class=hljs-built_in >Float64</span>)/t_it</code></pre>
<p><code>T_tot</code> is probably a bit lower than in the above experiment, but still rather close to <code>T_peak</code>.</p>
<p>Congratulations&#33; You have successfully made it through the memory copy kernel optimization experiments and learn about the fundamental parameters determining memory throughput. From now on you will get your hands dirty&#33;</p>
<p>One moment&#33; For the following exercises you will need the parameters we have established here for best memory access:</p>
<pre><code class="julia hljs">println(<span class=hljs-string >&quot;nx=ny=<span class=hljs-variable >$nx</span>; threads=<span class=hljs-variable >$threads</span>; blocks=<span class=hljs-variable >$blocks</span>&quot;</span>)</code></pre>
<h1 id=gpu_computing_and_kernel_programming ><a href="#gpu_computing_and_kernel_programming" class=header-anchor >GPU computing and kernel programming</a></h1>

<p><a href="#content">⤴ <em><strong>back to Content</strong></em></a></p>
<h1 id=exercises_-_lecture_6 ><a href="#exercises_-_lecture_6" class=header-anchor >Exercises - lecture 6</a></h1>
<div class=warning ><div class=title >⚠️ Warning&#33;</div>
<div class=messg ><p><strong>Exercise 1 has to be handed in as Jupyter notebook</strong> on Moodle and included in the this week&#39;s exercise folder on your GitHub repository.</p>
<p>Other exercises have to be handed in, as usual, as monolithic Julia scripts &#40;one code per script&#41; and uploaded to your private &#40;shared&#41; GitHub repository, in a <strong>specific folder for each lecture</strong>. The git commit hash &#40;or SHA&#41; of the final push needs to be uploaded on Moodle &#40;<a href="/course-101-0250-00/homework">more</a>&#41;.</p></div></div>
<h2 id=excercise_1_-_data_transfer_optimisations ><a href="#excercise_1_-_data_transfer_optimisations" class=header-anchor >Excercise 1 - <strong>Data transfer optimisations</strong></a></h2>
<p>👉 See <a href="/course-101-0250-00/logistics/#submission">Logistics</a> for submission details.</p>
<p>The goal of this exercise is to:</p>
<ul>
<li><p>learn how to minimize redundant main memory transfers and understand its importance;</p>

<li><p>understand the limits of the <em>total memory throughput</em> metric for performance evaluation;</p>

<li><p>learn how to compute the <em>effective memory throughput</em> and understand its interest;</p>

<li><p>learn about GPU array and kernel programming on the way.</p>

</ul>
<p>Prerequisites:</p>
<ul>
<li><p>the lecture 6 <em>Benchmarking memory copy and establishing peak memory access performance</em> &#40;<a href="https://github.com/eth-vaw-glaciology/course-101-0250-00/blob/main/slide-notebooks/notebooks/l6_1-gpu-memcopy.ipynb"><code>l6_1-gpu-memcopy.ipynb</code></a>&#41;</p>

</ul>
<h3 id=getting_started ><a href="#getting_started" class=header-anchor >Getting started</a></h3>
<p>Download the <a href="https://github.com/eth-vaw-glaciology/course-101-0250-00/blob/main/exercise-notebooks/notebooks/lecture6_ex1.ipynb"><code>lecture6_ex1.ipynb</code></a> notebook and edit it <em>&#40;you should have a copy on it in your <code>lecture06</code> folder on octopus&#41;</em>.</p>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >Values reported in this exercise are for the Nvidia P100 16GB PCIe GPU. You are running on Nvidia Tesla V100 32GB SXM2. Comparing the values you get - it may show that one cannot expect a fine tuned strategy to work always 100&#37; well on future &#40;or past&#41; architectures.</div></div>
<p>We will again use the packages <code>CUDA</code>, <code>BenchmarkTools</code> and <code>Plots</code> to create a little performance laboratory:</p>
<pre><code class="julia hljs"><span class=hljs-keyword >using</span> IJulia
<span class=hljs-keyword >using</span> CUDA
<span class=hljs-keyword >using</span> BenchmarkTools
<span class=hljs-keyword >using</span> Plots</code></pre>
<p>Let us consider the following 2-D heat diffusion solver &#40;the comments explain the code&#41;:</p>
<pre><code class="julia hljs"><span class=hljs-keyword >function</span> diffusion2D()
    <span class=hljs-comment ># Physics</span>
    lam      = <span class=hljs-number >1.0</span>                                          <span class=hljs-comment ># Thermal conductivity</span>
    c0       = <span class=hljs-number >2.0</span>                                          <span class=hljs-comment ># Heat capacity</span>
    lx, ly   = <span class=hljs-number >1.0</span>, <span class=hljs-number >1.0</span>                                     <span class=hljs-comment ># Length of computational domain in dimension x and y</span>

    <span class=hljs-comment ># Numerics</span>
    nx, ny   = <span class=hljs-number >32</span>*<span class=hljs-number >2</span>, <span class=hljs-number >32</span>*<span class=hljs-number >2</span>                                   <span class=hljs-comment ># Number of gridpoints in dimensions x and y</span>
    nt       = <span class=hljs-number >100</span>                                          <span class=hljs-comment ># Number of time steps</span>
    dx       = lx/(nx-<span class=hljs-number >1</span>)                                    <span class=hljs-comment ># Space step in x-dimension</span>
    dy       = ly/(ny-<span class=hljs-number >1</span>)                                    <span class=hljs-comment ># Space step in y-dimension</span>
    _dx, _dy = <span class=hljs-number >1.0</span>/dx, <span class=hljs-number >1.0</span>/dy

    <span class=hljs-comment ># Array initializations</span>
    T    = CUDA.zeros(<span class=hljs-built_in >Float64</span>, nx, ny)                      <span class=hljs-comment ># Temperature</span>
    Ci   = CUDA.zeros(<span class=hljs-built_in >Float64</span>, nx, ny)                      <span class=hljs-comment ># 1/Heat capacity</span>
    qTx  = CUDA.zeros(<span class=hljs-built_in >Float64</span>, nx-<span class=hljs-number >1</span>, ny-<span class=hljs-number >2</span>)                  <span class=hljs-comment ># Heat flux, x component</span>
    qTy  = CUDA.zeros(<span class=hljs-built_in >Float64</span>, nx-<span class=hljs-number >2</span>, ny-<span class=hljs-number >1</span>)                  <span class=hljs-comment ># Heat flux, y component</span>
    dTdt = CUDA.zeros(<span class=hljs-built_in >Float64</span>, nx-<span class=hljs-number >2</span>, ny-<span class=hljs-number >2</span>)                  <span class=hljs-comment ># Change of Temperature in time</span>

    <span class=hljs-comment ># Initial conditions</span>
    Ci .= <span class=hljs-number >1</span>/c0                                              <span class=hljs-comment ># 1/Heat capacity (could vary in space)</span>
    T  .= CuArray([<span class=hljs-number >10.0</span>*exp(-(((ix-<span class=hljs-number >1</span>)*dx-lx/<span class=hljs-number >2</span>)/<span class=hljs-number >2</span>)^<span class=hljs-number >2</span>-(((iy-<span class=hljs-number >1</span>)*dy-ly/<span class=hljs-number >2</span>)/<span class=hljs-number >2</span>)^<span class=hljs-number >2</span>) <span class=hljs-keyword >for</span> ix=<span class=hljs-number >1</span>:size(T,<span class=hljs-number >1</span>), iy=<span class=hljs-number >1</span>:size(T,<span class=hljs-number >2</span>)]) <span class=hljs-comment ># Initialization of Gaussian temperature anomaly</span>

    <span class=hljs-comment ># Time loop</span>
    dt  = min(dx^<span class=hljs-number >2</span>,dy^<span class=hljs-number >2</span>)/lam/maximum(Ci)/<span class=hljs-number >4.1</span>                <span class=hljs-comment ># Time step for 2D Heat diffusion</span>
    opts = (aspect_ratio=<span class=hljs-number >1</span>, xlims=(<span class=hljs-number >1</span>, nx), ylims=(<span class=hljs-number >1</span>, ny), clims=(<span class=hljs-number >0.0</span>, <span class=hljs-number >10.0</span>), c=:davos, xlabel=<span class=hljs-string >&quot;Lx&quot;</span>, ylabel=<span class=hljs-string >&quot;Ly&quot;</span>) <span class=hljs-comment ># plotting options</span>
    <span class=hljs-keyword >for</span> it = <span class=hljs-number >1</span>:nt
        diffusion2D_step!(T, Ci, qTx, qTy, dTdt, lam, dt, _dx, _dy) <span class=hljs-comment ># Diffusion time step.</span>
        IJulia.clear_output(<span class=hljs-literal >true</span>)
        display(heatmap(<span class=hljs-built_in >Array</span>(T)&#x27;; opts...))                <span class=hljs-comment ># Visualization</span>
    <span class=hljs-keyword >end</span>
<span class=hljs-keyword >end</span></code></pre>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >Divisions are precomputed as they are slower than multiplications.</div></div>
<p>The function to compute an actual time step is still missing to complete this solver. It can be written, e.g., as follows with finite differences using GPU <em>array programming</em> &#40;AP&#41;:</p>
<pre><code class="julia hljs"><span class=hljs-meta >@inbounds</span> <span class=hljs-meta >@views</span> <span class=hljs-keyword >macro</span> d_xa(A) esc(:( ($A[<span class=hljs-number >2</span>:<span class=hljs-keyword >end</span>  , :     ] .- $A[<span class=hljs-number >1</span>:<span class=hljs-keyword >end</span>-<span class=hljs-number >1</span>, :     ]) )) <span class=hljs-keyword >end</span>
<span class=hljs-meta >@inbounds</span> <span class=hljs-meta >@views</span> <span class=hljs-keyword >macro</span> d_xi(A) esc(:( ($A[<span class=hljs-number >2</span>:<span class=hljs-keyword >end</span>  ,<span class=hljs-number >2</span>:<span class=hljs-keyword >end</span>-<span class=hljs-number >1</span>] .- $A[<span class=hljs-number >1</span>:<span class=hljs-keyword >end</span>-<span class=hljs-number >1</span>,<span class=hljs-number >2</span>:<span class=hljs-keyword >end</span>-<span class=hljs-number >1</span>]) )) <span class=hljs-keyword >end</span>
<span class=hljs-meta >@inbounds</span> <span class=hljs-meta >@views</span> <span class=hljs-keyword >macro</span> d_ya(A) esc(:( ($A[ :     ,<span class=hljs-number >2</span>:<span class=hljs-keyword >end</span>  ] .- $A[ :     ,<span class=hljs-number >1</span>:<span class=hljs-keyword >end</span>-<span class=hljs-number >1</span>]) )) <span class=hljs-keyword >end</span>
<span class=hljs-meta >@inbounds</span> <span class=hljs-meta >@views</span> <span class=hljs-keyword >macro</span> d_yi(A) esc(:( ($A[<span class=hljs-number >2</span>:<span class=hljs-keyword >end</span>-<span class=hljs-number >1</span>,<span class=hljs-number >2</span>:<span class=hljs-keyword >end</span>  ] .- $A[<span class=hljs-number >2</span>:<span class=hljs-keyword >end</span>-<span class=hljs-number >1</span>,<span class=hljs-number >1</span>:<span class=hljs-keyword >end</span>-<span class=hljs-number >1</span>]) )) <span class=hljs-keyword >end</span>
<span class=hljs-meta >@inbounds</span> <span class=hljs-meta >@views</span> <span class=hljs-keyword >macro</span>  inn(A) esc(:( $A[<span class=hljs-number >2</span>:<span class=hljs-keyword >end</span>-<span class=hljs-number >1</span>,<span class=hljs-number >2</span>:<span class=hljs-keyword >end</span>-<span class=hljs-number >1</span>]                          )) <span class=hljs-keyword >end</span>

<span class=hljs-meta >@inbounds</span> <span class=hljs-meta >@views</span> <span class=hljs-keyword >function</span> diffusion2D_step!(T, Ci, qTx, qTy, dTdt, lam, dt, _dx, _dy)
    qTx     .= .-lam.*<span class=hljs-meta >@d_xi</span>(T).*_dx                              <span class=hljs-comment ># Fourier&#x27;s law of heat conduction: qT_x  = -λ ∂T/∂x</span>
    qTy     .= .-lam.*<span class=hljs-meta >@d_yi</span>(T).*_dy                              <span class=hljs-comment ># ...                               qT_y  = -λ ∂T/∂y</span>
    dTdt    .= <span class=hljs-meta >@inn</span>(Ci).*(.-<span class=hljs-meta >@d_xa</span>(qTx).*_dx .- <span class=hljs-meta >@d_ya</span>(qTy).*_dy)  <span class=hljs-comment ># Conservation of energy:           ∂T/∂t = 1/cp (-∂qT_x/∂x - ∂qT_y/∂y)</span>
    <span class=hljs-meta >@inn</span>(T) .= <span class=hljs-meta >@inn</span>(T) .+ dt.*dTdt                               <span class=hljs-comment ># Update of temperature             T_new = T_old + ∂t ∂T/∂t</span>
<span class=hljs-keyword >end</span></code></pre>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >We use everywhere views to avoid allocations of temporary arrays &#40;see <a href="https://docs.julialang.org/en/v1/manual/performance-tips/#man-performance-views">here</a> for more information&#41;.</div></div>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >We use everywhere dots to fuse vectorized operations and avoid any allocations of temporary arrays &#40;see <a href="https://docs.julialang.org/en/v1/manual/performance-tips/#More-dots:-Fuse-vectorized-operations">here</a> for more information&#41;. We wrote all dots explicitly for clarity; the <a href="https://docs.julialang.org/en/v1/base/arrays/#Base.Broadcast.@__dot__">macro <code>@.</code></a> removes the need of writing all dots explicitly.</div></div>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >We use simple macros to enable nice syntax, in particular macros can be used also on the left side of an equal sign &#40;learn <a href="https://docs.julialang.org/en/v1/manual/metaprogramming/#man-macros">here</a> more about macros&#41;.</div></div>
<p>Run now the 2-D heat diffusion solver to verify that it is working:</p>
<pre><code class="julia hljs">diffusion2D()</code></pre>
<h3 id=task_1_benchmarking ><a href="#task_1_benchmarking" class=header-anchor >Task 1 &#40;Benchmarking&#41;</a></h3>
<p>Benchmark the function <code>diffusion2D_step&#33;</code> using BenchmarkTools and compute a straightforward <em>lower bound of the total memory throughput</em>, <code>T_tot_lb</code>; then, compare it to the <em>peak memory throughput</em>, <code>T_peak</code>. You can compute <code>T_tot_lb</code> considering only full array reads and writes and knowing that there is no data reuse between different GPU array computation statements as each statement is translated into a separate and independently launched kernel &#40;note that to obtain the actual <code>T_tot</code>, one would need to use a profiler&#41;.</p>
<p>Furthermore, use the <code>nx&#61;ny</code> found best in the introduction notebook &#40;<code>1_memorycopy.ipynb</code>&#41; to allocate the necessary arrays if the amount of memory of your GPU allows it &#40;else divide this <code>nx</code> and <code>ny</code> by 2&#41;.</p>
<p>To help you, there is already some code below to initialize the required arrays and scalars for the benchmarking. <div class=note ><div class=title >💡 Note</div>
<div class=messg ><strong>hint</strong>: Do not forget to interpolate these predefined variables into the benchmarking expression using <code>&#36;</code> and note that you do not need to call the solver itself &#40;<code>diffusion2D</code>&#41;&#33;</div></div></p>
<pre><code class="julia hljs">nx = ny = <span class=hljs-comment ># complete!</span>
T    = CUDA.rand(<span class=hljs-built_in >Float64</span>, nx, ny);
Ci   = CUDA.rand(<span class=hljs-built_in >Float64</span>, nx, ny);
qTx  = CUDA.zeros(<span class=hljs-built_in >Float64</span>, nx-<span class=hljs-number >1</span>, ny-<span class=hljs-number >2</span>);
qTy  = CUDA.zeros(<span class=hljs-built_in >Float64</span>, nx-<span class=hljs-number >2</span>, ny-<span class=hljs-number >1</span>);
dTdt = CUDA.zeros(<span class=hljs-built_in >Float64</span>, nx-<span class=hljs-number >2</span>, ny-<span class=hljs-number >2</span>);
lam = _dx = _dy = dt = rand();</code></pre>
<pre><code class="julia hljs"><span class=hljs-comment ># solution</span>
t_it = <span class=hljs-meta >@belapsed</span> <span class=hljs-keyword >begin</span> ... <span class=hljs-keyword >end</span>
T_tot_lb = .../<span class=hljs-number >1e9</span>*nx*ny*sizeof(<span class=hljs-built_in >Float64</span>)/t_it</code></pre>
<p>Save the measured minimal runtime and the computed <code>T_tot_lb</code> in other variables &#40;<code>t_it_task1</code> and <code>T_tot_lb_task1</code>&#41; in order not to overwrite them later &#40;adapt these two lines if you used other variable names&#33;&#41;; moreover, we will remove the arrays we do no longer need in order to save space:</p>
<pre><code class="julia hljs">t_it_task1 = t_it
T_tot_lb_task1 = T_tot_lb
CUDA.unsafe_free!(qTx)
CUDA.unsafe_free!(qTy)
CUDA.unsafe_free!(dTdt)</code></pre>
<p><code>T_tot_lb</code> should be relatively close to <code>T_peak</code>. Nevertheless, one could do these computations at least three times faster. You may wonder why it is possible to predict that just looking at the code. It is because three of the four arrays that are updated every iteration are not computed based on their values in the previous iteration and their individual values could therefore be computed on-the-fly when needed or stored in the much faster on-chip memory as intermediate results; these three arrays would never need to be stored in main memory and read from there. Only the temperature array &#40;<code>T</code>&#41; needs inevitably to be read from main memory and written to it at every iteration as is computed based on its values from the previous iteration &#40;and the entire temperature array is orders of magnitudes bigger than the available on-chip memory&#41;. In addition, the heat capacity array &#40;<code>Ci</code>&#41; needs to be entirely read at every iteration. To sum up, only three of eleven full array memory reads or writes cannot be avoided. If we avoid them, we reduce the main memory accesses by more than a factor three and can therefore expect the code to be at least three times faster.</p>
<p>As a consequence, <code>T_tot</code> and <code>T_tot_lb</code> are often not good metrics to evaluate the optimality of an implementation. Based on these reflections, we will introduce a better metric for the performance evaluation of solvers as the above. But first, let us verify that we can indeed speed up these computations by a factor three or more.</p>
<p>With GPU kernel programming, we could do that as just described, fusing the four kernels that correspond to the four GPU array programming statements into one. However, we want to try an easier solution using GPU array programming at this point.</p>
<p>There is, however, no obvious way to compute values on-the-fly when needed or to store intermediate result on chip in order to achieve the above described. We can instead do the equivalent mathematically: we can substitute <code>qTx</code> and <code>qTy</code> into the expression to compute <code>dTdt</code> and then substitute this in turn into the expression to compute <code>T</code> to get:</p>
<span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><msub><mi>T</mi><mrow><mi mathvariant=normal >n</mi><mi mathvariant=normal >e</mi><mi mathvariant=normal >w</mi></mrow></msub><mo>=</mo><msub><mi>T</mi><mrow><mi mathvariant=normal >o</mi><mi mathvariant=normal >l</mi><mi mathvariant=normal >d</mi></mrow></msub><mo>+</mo><mi mathvariant=normal >∂</mi><mi>t</mi><mtext> </mtext><mfrac><mn>1</mn><msub><mi>c</mi><mi>p</mi></msub></mfrac><mrow><mo fence=true >(</mo><mo>−</mo><mfrac><mi mathvariant=normal >∂</mi><mrow><mi mathvariant=normal >∂</mi><mi>x</mi></mrow></mfrac><mrow><mo fence=true >(</mo><mo>−</mo><mi>λ</mi><mtext> </mtext><mfrac><mrow><mi mathvariant=normal >∂</mi><mi>T</mi></mrow><mrow><mi mathvariant=normal >∂</mi><mi>x</mi></mrow></mfrac><mo fence=true >)</mo></mrow><mo>−</mo><mfrac><mi mathvariant=normal >∂</mi><mrow><mi mathvariant=normal >∂</mi><mi>y</mi></mrow></mfrac><mrow><mo fence=true >(</mo><mo>−</mo><mi>λ</mi><mtext> </mtext><mfrac><mrow><mi mathvariant=normal >∂</mi><mi>T</mi></mrow><mrow><mi mathvariant=normal >∂</mi><mi>y</mi></mrow></mfrac><mo fence=true >)</mo></mrow><mo fence=true >)</mo></mrow></mrow><annotation encoding="application/x-tex"> T_\mathrm{new} = T_\mathrm{old} + ∂t~\frac{1}{c_p} \left( -\frac{∂}{∂x} \left(-λ~\frac{∂T}{∂x}\right) -\frac{∂}{∂y} \left(-λ~\frac{∂T}{∂y}\right) \right) </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">n</span><span class="mord mathrm mtight">e</span><span class="mord mathrm mtight" style="margin-right:0.01389em;">w</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">o</span><span class="mord mathrm mtight">l</span><span class="mord mathrm mtight">d</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:2.4221079999999997em;vertical-align:-0.972108em;"></span><span class=mord  style="margin-right:0.05556em;">∂</span><span class="mord mathnormal">t</span><span class="mspace nobreak"> </span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.32144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord ><span class="mord mathnormal">c</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.286108em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.972108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class=mord >−</span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.37144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord  style="margin-right:0.05556em;">∂</span><span class="mord mathnormal">x</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord  style="margin-right:0.05556em;">∂</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class=mord >−</span><span class="mord mathnormal">λ</span><span class="mspace nobreak"> </span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.37144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord  style="margin-right:0.05556em;">∂</span><span class="mord mathnormal">x</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord  style="margin-right:0.05556em;">∂</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >−</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.37144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord  style="margin-right:0.05556em;">∂</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord  style="margin-right:0.05556em;">∂</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class=mord >−</span><span class="mord mathnormal">λ</span><span class="mspace nobreak"> </span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.37144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord  style="margin-right:0.05556em;">∂</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord  style="margin-right:0.05556em;">∂</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span></span></span></span></span>
<p>Note that this would obviously be mathematically equivalent to the temperature update rule that we would obtain based on the commonly used heat diffusion equation <strong>for constant and scalar</strong> <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">λ</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">λ</span></span></span></span> and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">c_p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.716668em;vertical-align:-0.286108em;"></span><span class=mord ><span class="mord mathnormal">c</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>:</p>
<span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><msub><mi>T</mi><mrow><mi mathvariant=normal >n</mi><mi mathvariant=normal >e</mi><mi mathvariant=normal >w</mi></mrow></msub><mo>=</mo><msub><mi>T</mi><mrow><mi mathvariant=normal >o</mi><mi mathvariant=normal >l</mi><mi mathvariant=normal >d</mi></mrow></msub><mo>+</mo><mi mathvariant=normal >∂</mi><mi>t</mi><mtext> </mtext><mfrac><mi>λ</mi><msub><mi>c</mi><mi>p</mi></msub></mfrac><mrow><mo fence=true >(</mo><mfrac><mrow><msup><mi mathvariant=normal >∂</mi><mn>2</mn></msup><mi>T</mi></mrow><mrow><mi mathvariant=normal >∂</mi><msup><mi>x</mi><mn>2</mn></msup></mrow></mfrac><mo>+</mo><mfrac><mrow><msup><mi mathvariant=normal >∂</mi><mn>2</mn></msup><mi>T</mi></mrow><mrow><mi mathvariant=normal >∂</mi><msup><mi>y</mi><mn>2</mn></msup></mrow></mfrac><mo fence=true >)</mo></mrow></mrow><annotation encoding="application/x-tex"> T_\mathrm{new} = T_\mathrm{old} + ∂t~\frac{λ}{c_p} \left( \frac{∂^2T}{∂x^2} + \frac{∂^2T}{∂y^2} \right) </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">n</span><span class="mord mathrm mtight">e</span><span class="mord mathrm mtight" style="margin-right:0.01389em;">w</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">o</span><span class="mord mathrm mtight">l</span><span class="mord mathrm mtight">d</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:2.463216em;vertical-align:-0.972108em;"></span><span class=mord  style="margin-right:0.05556em;">∂</span><span class="mord mathnormal">t</span><span class="mspace nobreak"> </span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.37144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord ><span class="mord mathnormal">c</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.286108em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal">λ</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.972108em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.491108em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord  style="margin-right:0.05556em;">∂</span><span class=mord ><span class="mord mathnormal">x</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.740108em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord ><span class=mord  style="margin-right:0.05556em;">∂</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.491108em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord  style="margin-right:0.05556em;">∂</span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.740108em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord ><span class=mord  style="margin-right:0.05556em;">∂</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span></span></span></span></span>
<p>We will though use &#40;2&#41; in order not to make limiting assumptions and simplify the computations done in <code>diffusion2D_step&#33;</code>, but to solely optimize data transfer.</p>
<p>We remove therefore the arrays <code>qTx</code>, <code>qTy</code> and <code>dTdt</code> in the main function of the 2-D heat diffusion solver as they are no longer needed; moreover, we introduce <code>T2</code> as a second array for the temperature. <code>T2</code> is needed to write newly computed temperature values to a different location then the old temperature values while they are still needed for computations &#40;else we would perform the spatial derivatives partly with new temperature values instead of only with old ones&#41;. Here is the resulting main function:</p>
<pre><code class="julia hljs"><span class=hljs-keyword >function</span> diffusion2D()
    <span class=hljs-comment ># Physics</span>
    lam      = <span class=hljs-number >1.0</span>                                          <span class=hljs-comment ># Thermal conductivity</span>
    c0       = <span class=hljs-number >2.0</span>                                          <span class=hljs-comment ># Heat capacity</span>
    lx, ly   = <span class=hljs-number >1.0</span>, <span class=hljs-number >1.0</span>                                     <span class=hljs-comment ># Length of computational domain in dimension x and y</span>

    <span class=hljs-comment ># Numerics</span>
    nx, ny   = <span class=hljs-number >32</span>*<span class=hljs-number >2</span>, <span class=hljs-number >32</span>*<span class=hljs-number >2</span>                                   <span class=hljs-comment ># Number of gridpoints in dimensions x and y</span>
    nt       = <span class=hljs-number >100</span>                                          <span class=hljs-comment ># Number of time steps</span>
    dx       = lx/(nx-<span class=hljs-number >1</span>)                                    <span class=hljs-comment ># Space step in x-dimension</span>
    dy       = ly/(ny-<span class=hljs-number >1</span>)                                    <span class=hljs-comment ># Space step in y-dimension</span>
    _dx, _dy = <span class=hljs-number >1.0</span>/dx, <span class=hljs-number >1.0</span>/dy

    <span class=hljs-comment ># Array initializations</span>
    T    = CUDA.zeros(<span class=hljs-built_in >Float64</span>, nx, ny)                      <span class=hljs-comment ># Temperature</span>
    T2   = CUDA.zeros(<span class=hljs-built_in >Float64</span>, nx, ny)                      <span class=hljs-comment ># 2nd array for Temperature</span>
    Ci   = CUDA.zeros(<span class=hljs-built_in >Float64</span>, nx, ny)                      <span class=hljs-comment ># 1/Heat capacity</span>

    <span class=hljs-comment ># Initial conditions</span>
    Ci .= <span class=hljs-number >1</span>/c0                                              <span class=hljs-comment ># 1/Heat capacity (could vary in space)</span>
    T  .= CuArray([<span class=hljs-number >10.0</span>*exp(-(((ix-<span class=hljs-number >1</span>)*dx-lx/<span class=hljs-number >2</span>)/<span class=hljs-number >2</span>)^<span class=hljs-number >2</span>-(((iy-<span class=hljs-number >1</span>)*dy-ly/<span class=hljs-number >2</span>)/<span class=hljs-number >2</span>)^<span class=hljs-number >2</span>) <span class=hljs-keyword >for</span> ix=<span class=hljs-number >1</span>:size(T,<span class=hljs-number >1</span>), iy=<span class=hljs-number >1</span>:size(T,<span class=hljs-number >2</span>)]) <span class=hljs-comment ># Initialization of Gaussian temperature anomaly</span>
    T2 .= T;                                                 <span class=hljs-comment ># Assign also T2 to get correct boundary conditions.</span>

    <span class=hljs-comment ># Time loop</span>
    dt  = min(dx^<span class=hljs-number >2</span>,dy^<span class=hljs-number >2</span>)/lam/maximum(Ci)/<span class=hljs-number >4.1</span>                <span class=hljs-comment ># Time step for 2D Heat diffusion</span>
    opts = (aspect_ratio=<span class=hljs-number >1</span>, xlims=(<span class=hljs-number >1</span>, nx), ylims=(<span class=hljs-number >1</span>, ny), clims=(<span class=hljs-number >0.0</span>, <span class=hljs-number >10.0</span>), c=:davos, xlabel=<span class=hljs-string >&quot;Lx&quot;</span>, ylabel=<span class=hljs-string >&quot;Ly&quot;</span>) <span class=hljs-comment ># plotting options</span>
    <span class=hljs-keyword >for</span> it = <span class=hljs-number >1</span>:nt
        diffusion2D_step!(T2, T, Ci, lam, dt, _dx, _dy)     <span class=hljs-comment ># Diffusion time step.</span>
        IJulia.clear_output(<span class=hljs-literal >true</span>)
        display(heatmap(<span class=hljs-built_in >Array</span>(T)&#x27;; opts...))                <span class=hljs-comment ># Visualization</span>
        T, T2 = T2, T                                       <span class=hljs-comment ># Swap the aliases T and T2 (does not perform any array copy)</span>
    <span class=hljs-keyword >end</span>
<span class=hljs-keyword >end</span></code></pre>
<h3 id=task_2_gpu_array_programming ><a href="#task_2_gpu_array_programming" class=header-anchor >Task 2 &#40;GPU array programming&#41;</a></h3>
<p>Write the corresponding function <code>diffusion2D_step&#33;</code> to compute a time step using the temperature update rule &#40;2&#41;; write it in <strong>a single GPU array programming statement</strong> &#40;it should go over multiple lines&#41; and without using any helper macros or functions in order to be sure that all computations will get fused into one single kernel. <div class=note ><div class=title >💡 Note</div>
<div class=messg ><strong>hint</strong>: Make sure to use the correct function signature: <code>diffusion2D_step&#33;&#40;T2, T, Ci, lam, dt, _dx, _dy&#41;</code>.</div></div></p>
<div class=note ><div class=title >💡 Note</div>
<div class=messg ><strong>hint</strong>: To verify that it does the right computations, you can launch <code>diffusion2D&#40;&#41;</code>.</div></div>
<div class=note ><div class=title >💡 Note</div>
<div class=messg ><strong>hint</strong>: Only add the <code>@inbounds</code> macro to the function once you have verified that it work as they should. Remember that outside of these exercises it can be more convenient not to use the <code>@inbounds</code> macro, but to deactivate bounds checking instead globally for high performance runs by calling julia as follows : <code>julia --check-bounds&#61;no ...</code></div></div>
<pre><code class="julia hljs"><span class=hljs-comment ># solution</span>
<span class=hljs-meta >@inbounds</span> <span class=hljs-meta >@views</span> <span class=hljs-keyword >function</span> diffusion2D_step!(T2, T, Ci, lam, dt, _dx, _dy)
    T2[<span class=hljs-number >2</span>:<span class=hljs-keyword >end</span>-<span class=hljs-number >1</span>,<span class=hljs-number >2</span>:<span class=hljs-keyword >end</span>-<span class=hljs-number >1</span>] .= T[<span class=hljs-number >2</span>:<span class=hljs-keyword >end</span>-<span class=hljs-number >1</span>,<span class=hljs-number >2</span>:<span class=hljs-keyword >end</span>-<span class=hljs-number >1</span>] .+ dt.* ...
<span class=hljs-keyword >end</span></code></pre>
<h3 id=task_3_benchmarking ><a href="#task_3_benchmarking" class=header-anchor >Task 3 &#40;Benchmarking&#41;</a></h3>
<p>Benchmark the new function <code>diffusion2D_step&#33;</code> and compute the runtime speed-up compared to the function benchmarked in Task 1. Then, compute <code>T_tot_lb</code> and the ratio between this <code>T_tot_lb</code> and the one obtained in Task 1.</p>
<pre><code class="julia hljs"><span class=hljs-comment ># solution</span>
T2 = ...
t_it = <span class=hljs-meta >@belapsed</span> <span class=hljs-keyword >begin</span> ...; synchronize() <span class=hljs-keyword >end</span>
speedup = t_it_task1/t_it
T_tot_lb = .../<span class=hljs-number >1e9</span>*nx*ny*sizeof(<span class=hljs-built_in >Float64</span>)/t_it
ratio_T_tot_lb = ...</code></pre>
<p>Save the measured minimal runtime and the computed T<em>tot</em>lb in other variables &#40;<code>t_it_task3</code> and <code>T_tot_lb_task3</code>&#41; in order not to overwrite them later &#40;adapt these two lines if you used other variable names&#33;&#41;:</p>
<pre><code class="julia hljs">t_it_task3 = t_it
T_tot_lb_task3 = T_tot_lb</code></pre>
<p>You should have observed a significant speedup &#40;a speedup of factor 2 measured with the Tesla P100 GPU&#41; even though <code>T_tot_lb</code> has probably decreased &#40;to 214 GB/s with the Tesla P100 GPU, i.e about 56&#37; of <code>T_tot_lb</code> measured in task 1&#41;. This empirically confirms our earlier statement that <code>T_tot_lb</code> and consequently also <code>T_tot</code> &#40;measured with a profiler&#41; are often not good metrics to evaluate the <strong>optimality</strong> of an implementation.</p>
<p>A good metric should certainly be tightly linked to observed runtime. We will now try to further speedup the function <code>diffusion2D_step&#33;</code> using straightforward GPU kernel programming.</p>
<h3 id=task_4_gpu_kernel_programming ><a href="#task_4_gpu_kernel_programming" class=header-anchor >Task 4 &#40;GPU kernel programming&#41;</a></h3>
<p>Rewrite the function <code>diffusion2D_step&#33;</code> using GPU kernel programming: from within this function, call a GPU kernel, which updates the temperature using update rule &#40;2&#41; &#40;you also need to write this kernel&#41;; for simplicity&#39;s sake, hardcode the kernel launch parameter <code>threads</code> found best in the introduction &#40;<code>l6_1-gpu-memcopy.ipynb</code>&#41; into the function and compute <code>blocks</code> accordingly in order to have it work with the existing main function <code>diffusion2&#40;&#41;</code> &#40;use the function <code>size</code> instead of <code>nx</code> and <code>ny</code> to compute <code>blocks</code>&#41;. <div class=note ><div class=title >💡 Note</div>
<div class=messg >You can base yourself on the kernel <code>memcopy_triad_KP&#33;</code> from the introdution notebook to help you remember the very basics of GPU kernel programming.</div></div></p>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >In this kind of kernels, the computations are described for one array cell &#40;here <code>T2&#91;ix,iy&#93;</code>&#41; rather than for whole arrays - just like in a for loop; moreover, if-statements allow to ensure to remain within the array boundaries &#40;in for loop this is achieved with the loop ranges&#41;.</div></div>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >To verify that it does the right computations, you can launch <code>diffusion2D&#40;&#41;</code> &#40;as in task 2&#41;.</div></div>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >Add the <code>@inbounds</code> macro direcly in front of the Temperature assignement &#40;<code>T2&#91;ix,iy&#93;</code>&#41; as else it does not propagate to the computations &#40;more information on the propagation of <code>@inbounds</code> can be found <a href="https://docs.julialang.org/en/v1/devdocs/boundscheck/">here</a>; however, as noted earlier, outside of these exercises, it is often more convenient to activate and deactivate bounds-checking globally instead of using the <code>@inbounds</code> macro&#41;.</div></div>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >Only add the <code>@inbounds</code> macro to the function once you have verified that it work as they should &#40;as in task 2&#41;.</div></div>
<pre><code class="julia hljs"><span class=hljs-comment ># solution</span>
<span class=hljs-keyword >function</span> diffusion2D_step!(...)
    threads = (..., ...)
    blocks  = (size(...)÷threads[<span class=hljs-number >1</span>], size(...)÷threads[<span class=hljs-number >2</span>])
    <span class=hljs-meta >@cuda</span> ...
<span class=hljs-keyword >end</span>

<span class=hljs-keyword >function</span> update_temperature!(...)
    ix = ...
    iy = ...
    <span class=hljs-keyword >if</span> (ix... &amp;&amp; iy... )
        <span class=hljs-meta >@inbounds</span> T2[ix,iy] = T[ix,iy] + dt*(Ci[ix,iy]*( ... ))
    <span class=hljs-keyword >end</span>
    <span class=hljs-keyword >return</span>
<span class=hljs-keyword >end</span></code></pre>
<h3 id=task_5_benchmarking ><a href="#task_5_benchmarking" class=header-anchor >Task 5 &#40;Benchmarking&#41;</a></h3>
<p>Just like in Task 3, benchmark the new function <code>diffusion2D_step&#33;</code> and compute the runtime speedup compared to the function benchmarked in Task 1. Then, compute <code>T_tot_lb</code> and the ratio between this <code>T_tot_lb</code> and the one obtained in Task 1.</p>
<pre><code class="julia hljs"><span class=hljs-comment ># solution</span>
t_it = <span class=hljs-meta >@belapsed</span> <span class=hljs-keyword >begin</span> ...; synchronize() <span class=hljs-keyword >end</span>
speedup = ...
T_tot_lb = .../<span class=hljs-number >1e9</span>*nx*ny*sizeof(<span class=hljs-built_in >Float64</span>)/t_it
ratio_T_tot_lb = ...</code></pre>
<p>The runtime speedup is probably even higher &#40;a speedup of factor 4.9 measured with the Tesla P100 GPU&#41;, even though <code>T_tot_lb</code> is probably somewhat similar to the one obtained in task 1 &#40;524 GB/s with the Tesla P100 GPU, i.e about 36&#37; above <code>T_tot_lb</code> measured in task 1&#41;. We will now define a better metric for the performance evaluation of solvers like the one above, which is always proportional to observed runtime.</p>
<p>To this aim, let us recall first the reflections made after benchmarking the original GPU array programming code in Task 1:</p>
<blockquote>
<p>three of the four arrays that are updated every iteration are not computed based on their values in the previous iteration and their individual values could therefore be computed on-the-fly when needed or stored in the much faster on-chip memory as intermediate results; these three arrays would never need to be stored in main memory and read from there. Only the temperature array &#40;<code>T</code>&#41; needs inevitably to be read from main memory and written to it at every iteration as is computed based on its values from the previous iteration &#40;and the entire temperature array is orders of magnitudes bigger than the available on-chip memory&#41;. In addition, the heat capacity array &#40;<code>Ci</code>&#41; needs to be entirely read at every iteration. To sum up, only three of eleven full array memory reads or writes cannot be avoided. If we avoid them, we reduce the main memory accesses by more than a factor three and can therefore expect the code to be at least three times faster.</p>
</blockquote>
<p>With this in mind, we will now define the metric, which we call the <em>effective memory throughput</em>, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi mathvariant=normal >e</mi><mi mathvariant=normal >f</mi><mi mathvariant=normal >f</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_\mathrm{eff}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">e</span><span class="mord mathrm mtight" style="margin-right:0.07778em;">f</span><span class="mord mathrm mtight" style="margin-right:0.07778em;">f</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</p>
<p>The effective memory access, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi mathvariant=normal >e</mi><mi mathvariant=normal >f</mi><mi mathvariant=normal >f</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_\mathrm{eff}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal">A</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">e</span><span class="mord mathrm mtight" style="margin-right:0.07778em;">f</span><span class="mord mathrm mtight" style="margin-right:0.07778em;">f</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> &#91;GB&#93;, is the the sum of twice the memory footprint of the unknown fields, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mi mathvariant=normal >u</mi></msub></mrow><annotation encoding="application/x-tex">D_\mathrm{u}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">u</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, &#40;fields that depend on their own history and that need to be updated every iteration&#41; and the known fields, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mi mathvariant=normal >k</mi></msub></mrow><annotation encoding="application/x-tex">D_\mathrm{k}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">k</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, that do not change every iteration. The effective memory access divided by the execution time per iteration, t_it &#91;sec&#93;, defines the effective memory throughput, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi mathvariant=normal >e</mi><mi mathvariant=normal >f</mi><mi mathvariant=normal >f</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_\mathrm{eff}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">e</span><span class="mord mathrm mtight" style="margin-right:0.07778em;">f</span><span class="mord mathrm mtight" style="margin-right:0.07778em;">f</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> &#91;GB/s&#93;.</p>
<p>The upper bound of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi mathvariant=normal >e</mi><mi mathvariant=normal >f</mi><mi mathvariant=normal >f</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_\mathrm{eff}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">e</span><span class="mord mathrm mtight" style="margin-right:0.07778em;">f</span><span class="mord mathrm mtight" style="margin-right:0.07778em;">f</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi mathvariant=normal >p</mi><mi mathvariant=normal >e</mi><mi mathvariant=normal >a</mi><mi mathvariant=normal >k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_\mathrm{peak}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.969438em;vertical-align:-0.286108em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">p</span><span class="mord mathrm mtight">e</span><span class="mord mathrm mtight">a</span><span class="mord mathrm mtight">k</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> as measured e.g. by <a href="https://www.researchgate.net/publication/51992086_Memory_bandwidth_and_machine_balance_in_high_performance_computers">McCalpin, 1995</a> for CPUs or a GPU analogue. Defining the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi mathvariant=normal >e</mi><mi mathvariant=normal >f</mi><mi mathvariant=normal >f</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_\mathrm{eff}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">e</span><span class="mord mathrm mtight" style="margin-right:0.07778em;">f</span><span class="mord mathrm mtight" style="margin-right:0.07778em;">f</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> metric, we assume that 1&#41; we evaluate an iterative stencil-based solver, 2&#41; the problem size is much larger than the cache sizes and 3&#41; the usage of time blocking is not feasible or advantageous &#40;which is a reasonable assumption for real-world applications&#41;. An important concept is not to include fields within the effective memory access that do not depend on their own history &#40;e.g. fluxes&#41;; such fields can be re-computed on the fly or stored on-chip. Defining a theoretical upper bound for <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi mathvariant=normal >e</mi><mi mathvariant=normal >f</mi><mi mathvariant=normal >f</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_\mathrm{eff}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">e</span><span class="mord mathrm mtight" style="margin-right:0.07778em;">f</span><span class="mord mathrm mtight" style="margin-right:0.07778em;">f</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> that is closer to the real upper bound is work in progress.</p>
<h3 id=task_6_benchmarking ><a href="#task_6_benchmarking" class=header-anchor >Task 6 &#40;Benchmarking&#41;</a></h3>
<p>Compute the effective memory throughput, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi mathvariant=normal >e</mi><mi mathvariant=normal >f</mi><mi mathvariant=normal >f</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_\mathrm{eff}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">e</span><span class="mord mathrm mtight" style="margin-right:0.07778em;">f</span><span class="mord mathrm mtight" style="margin-right:0.07778em;">f</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, for the solvers benchmarked in Task 1, 3 and 5 &#40;you do not need to redo any benchmarking, but you can compute it based on the saved measured runtimes in these three tasks&#41; and recompute the speedup achieved in Task 3 and 5 based on <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi mathvariant=normal >e</mi><mi mathvariant=normal >f</mi><mi mathvariant=normal >f</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_\mathrm{eff}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">e</span><span class="mord mathrm mtight" style="margin-right:0.07778em;">f</span><span class="mord mathrm mtight" style="margin-right:0.07778em;">f</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> instead of based on the runtime; compare the newly computed speedups with the previous.</p>
<pre><code class="julia hljs"><span class=hljs-comment ># solution</span>
T_eff_task1 = .../t_it_task1
T_eff_task3 = .../t_it_task3
T_eff_task5 = .../t_it
speedup_Teff_task3 = T_eff_task3/T_eff_task1
speedup_Teff_task5 = T_eff_task5/T_eff_task1</code></pre>
<p>Did the speedups you recomputed differ from the previous ones?</p>
<p>If yes, then you made a mistake. Due to the way <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi mathvariant=normal >e</mi><mi mathvariant=normal >f</mi><mi mathvariant=normal >f</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_\mathrm{eff}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">e</span><span class="mord mathrm mtight" style="margin-right:0.07778em;">f</span><span class="mord mathrm mtight" style="margin-right:0.07778em;">f</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is defined, it is always proportional to observed runtime and it reflects therefore any runtime speedup by 100&#37; while the problem size and the number data type are kept fixed. If, however, you increase these parameters, then T_eff will reflect the additionally performed work and it therefore enables the comparison of the performance achieved in function of the problem size &#40;or number data type&#41;. It even allows to compare the performance of different solvers or implementations to a certain point.</p>
<p>Most importantly though, comparing a measured <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi mathvariant=normal >e</mi><mi mathvariant=normal >f</mi><mi mathvariant=normal >f</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_\mathrm{eff}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">e</span><span class="mord mathrm mtight" style="margin-right:0.07778em;">f</span><span class="mord mathrm mtight" style="margin-right:0.07778em;">f</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> with <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi mathvariant=normal >p</mi><mi mathvariant=normal >e</mi><mi mathvariant=normal >a</mi><mi mathvariant=normal >k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_\mathrm{peak}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.969438em;vertical-align:-0.286108em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">p</span><span class="mord mathrm mtight">e</span><span class="mord mathrm mtight">a</span><span class="mord mathrm mtight">k</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> informs us about room for performance improvement.</p>
<h3 id=task_7_benchmarking ><a href="#task_7_benchmarking" class=header-anchor >Task 7 &#40;Benchmarking&#41;</a></h3>
<p>Compute by how much percent you can improve the performance of the solver at most:</p>
<pre><code class="julia hljs"><span class=hljs-comment >#solution for V100</span>
T_peak = ... <span class=hljs-comment ># Peak memory throughput of the Tesla V100 GPU</span>
<span class=hljs-meta >@show</span> T_eff/T_peak</code></pre>

<p><a href="#content">⤴ <em><strong>back to Content</strong></em></a></p>
<hr />
<div class=page-foot >
  <div class=copyright >
    <a href="https://github.com/eth-vaw-glaciology/course-101-0250-00/"><b>Edit this page on <img class=github-logo  src="https://unpkg.com/ionicons@5.1.2/dist/svg/logo-github.svg"></b></a><br>
    Last modified: October 25, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
  </div>
</div>
</div>
    </div>