<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/course-101-0250-00/libs/katex/katex.min.css"> <link rel=stylesheet  href="/course-101-0250-00/libs/highlight/github.min.css"> <link rel=stylesheet  href="/course-101-0250-00/css/franklin.css"> <link rel=stylesheet  href="/course-101-0250-00/css/poole_hyde.css"> <link rel=stylesheet  href="/course-101-0250-00/css/custom.css"> <style> html {font-size: 17px;} .franklin-content {position: relative; padding-left: 8%; padding-right: 5%; line-height: 1.35em;} @media (min-width: 940px) { .franklin-content {width: 100%; margin-left: auto; margin-right: auto;} } @media (max-width: 768px) { .franklin-content {padding-left: 6%; padding-right: 6%;} } </style> <link rel=icon  href="/course-101-0250-00/assets/favicon.png"> <title>Lecture 5</title> <style> .content {max-width: 50rem} </style> <div class=sidebar > <div class="container sidebar-sticky"> <div class=sidebar-about > <img src="/course-101-0250-00/assets/vaw_logo.png" style="width: 180px; height: auto; display: inline"> <div style="font-weight: margin-bottom: 0.5em"><a href="/course-101-0250-00/"> Fall 2021</a> <span style="opacity: 0.7;">| <a href="http://www.vvz.ethz.ch/Vorlesungsverzeichnis/lerneinheit.view?semkez=2021W&ansicht=KATALOGDATEN&lerneinheitId=155538&lang=en"> ETHZ 101-0250-00</a></span></div> <br> <h1><a href="/course-101-0250-00/">Solving partial differential equations in parallel on GPUs</a></h1> <div style="line-height:18px; font-size: 15px; opacity: 0.85">by <a href="https://vaw.ethz.ch/en/people/person-detail.MjcwOTYw.TGlzdC8xOTYxLDE1MTczNjI1ODA=.html">Ludovic Räss</a>, <a href="https://vaw.ethz.ch/en/personen/person-detail.html?persid=124402">Mauro Werder</a> & <a href="https://www.cscs.ch/about/staff/">Samuel Omlin</a> </div> </div> <br> <style> </style> <nav class=sidebar-nav  style="opacity: 0.9"> <a class="sidebar-nav-item " href="/course-101-0250-00/"><b>Welcome</b></a> <a class="sidebar-nav-item " href="/course-101-0250-00/logistics/">Logistics</a> <a class="sidebar-nav-item " href="/course-101-0250-00/homework/">Homework</a> <a class="sidebar-nav-item " href="/course-101-0250-00/software_install/">Software install</a> <a class="sidebar-nav-item " href="/course-101-0250-00/extras/">Extras</a> <br> <div class=course-section >Part 1 - Introduction</div> <a class="sidebar-nav-item " href="/course-101-0250-00/lecture1/">Lecture 1</a> <a class="sidebar-nav-item " href="/course-101-0250-00/lecture2/">Lecture 2</a> <a class="sidebar-nav-item " href="/course-101-0250-00/lecture3/">Lecture 3</a> <a class="sidebar-nav-item " href="/course-101-0250-00/lecture4/">Lecture 4</a> <div class=course-section >Part 2 - Solving PDEs on GPUs</div> <a class="sidebar-nav-item active" href="/course-101-0250-00/lecture5/">Lecture 5</a> <a class="sidebar-nav-item " href="/course-101-0250-00/lecture6/">Lecture 6</a> <a class="sidebar-nav-item " href="/course-101-0250-00/lecture7/">Lecture 7</a> <a class="sidebar-nav-item " href="/course-101-0250-00/lecture8/">Lecture 8</a> <div class=course-section >Part 3 - Projects</div> <br> </nav> </div> </div> <div class="content container"> <div class=franklin-content > <h1 id=lecture_5 ><a href="#lecture_5" class=header-anchor >Lecture 5</a></h1> <blockquote> <p><strong>Agenda</strong><br />📚 Parallel computing on CPUs &amp; performance assessment, the \(T_\mathrm{eff}\) metric<br />💻 Unit testing in Julia<br />🚧 Exercises:</p> <ul> <li><p>CPU perf. codes for diffusion and acoustic waves</p> <li><p>Unit tests and testset implementation</p> </ul> </blockquote> <p><hr /> </p> <p><a id=content  class=anchor ></a> <strong>Content</strong></p> <div class=franklin-toc ><ol><li><a href="#lecture_5">Lecture 5</a><li><a href="#parallel_computing_on_cpus_and_performance_assessment">Parallel computing &#40;on CPUs&#41; and performance assessment</a><ol><li><a href="#performance_limiters">Performance limiters</a><li><a href="#effective_memory_throughput_metric_t_mathrmeff">Effective memory throughput metric \(T_\mathrm{eff}\)</a><li><a href="#parallel_computing_on_cpus">Parallel computing on CPUs</a><li><a href="#shared_memory_parallelisation">Shared memory parallelisation</a></ol><li><a href="#unit_testing_in_julia">Unit testing in Julia</a><ol><li><a href="#basic_unit_tests">Basic unit tests</a><li><a href="#working_with_a_test_sets">Working with a test sets</a></ol><li><a href="#exercises_-_lecture_5">Exercises - lecture 5</a><ol><li><a href="#exercise_1_-_performance_implementation_diffusion_2d">Exercise 1 - <strong>Performance implementation: Diffusion 2D</strong></a><li><a href="#exercise_2_-_performance_implementation_acoustic_2d">Exercise 2 - <strong>Performance implementation: Acoustic 2D</strong></a><li><a href="#exercise_3_-_performance_evaluation">Exercise 3 - <strong>Performance evaluation</strong></a><li><a href="#exercise_4_-_unit_tests">Exercise 4 - <strong>Unit tests</strong></a></ol></ol></div> <p><a href="#exercises_-_lecture_5"><em>👉 get started with exercises</em></a></p> <hr /> <h1 id=parallel_computing_on_cpus_and_performance_assessment ><a href="#parallel_computing_on_cpus_and_performance_assessment" class=header-anchor >Parallel computing &#40;on CPUs&#41; and performance assessment</a></h1> <h3 id=the_goal_of_this_lecture_5_is_to_introduce ><a href="#the_goal_of_this_lecture_5_is_to_introduce" class=header-anchor >The goal of this lecture 5 is to introduce:</a></h3> <ul> <li><p>Performance limiters</p> <li><p>Effective memory throughput metric \(T_\mathrm{eff}\)</p> <li><p>Parallel computing on CPUs</p> <li><p>Shared memory parallelisation</p> </ul> <h2 id=performance_limiters ><a href="#performance_limiters" class=header-anchor >Performance limiters</a></h2> <h3 id=hardware ><a href="#hardware" class=header-anchor >Hardware</a></h3> <ul> <li><p>GPUs are throughput-oriented systems</p> <li><p>GPUs use their parallelism to hide latency</p> <li><p>Some multi-core CPUs have many cores nowadays - similar challenges ?</p> </ul> <p><em>Recall from <a href="lecture1/#why_we_do_it">lecture 1</a> ...</em></p> <p>Use <strong>parallel computing</strong> &#40;to address this&#41;:</p> <ul> <li><p>The &quot;memory wall&quot; in ~ 2004</p> <li><p>Single-core to multi-core devices</p> </ul> <p><img src="../assets/literate_figures/mem_wall.png" alt=mem_wall  /></p> <p>GPUs are massively parallel devices</p> <ul> <li><p>SIMD machine &#40;programmed using threads - SPMD&#41; &#40;<a href="https://safari.ethz.ch/architecture/fall2020/lib/exe/fetch.php?media&#61;onur-comparch-fall2020-lecture24-simdandgpu-afterlecture.pdf">more</a>&#41;</p> <li><p>Further increases the Flop vs Bytes gap</p> </ul> <p><img src="../assets/literate_figures/cpu_gpu_evo.png" alt=cpu_gpu_evo  /></p> <p>Taking a look at a recent GPU and CPU:</p> <ul> <li><p>Nvidia Tesla A100 GPU</p> <li><p>AMD EPYC &quot;Rome&quot; 7282 &#40;16 cores&#41; CPU</p> </ul> <table><tr><th align=center >Device<th align=center >TFLOP/s &#40;FP64&#41;<th align=center >Memory BW TB/s<tr><td align=center >Tesla A100<td align=center >9.7<td align=center >1.55<tr><td align=center >AMD EPYC 7282<td align=center >0.7<td align=center >0.085</table> <p>Current GPUs &#40;and CPUs&#41; can do many more computations in a given amount of time than they can access numbers from main memory.</p> <p>Quantify the imbalance:</p> \[ \frac{\mathrm{computation\;peak\;performance\;[TFLOP/s]}}{\mathrm{memory\;access\;peak\;performance\;[TB/s]}} × \mathrm{size\;of\;a\;number\;[Bytes]} \] <p><em>&#40;Theoretical peak performance values as specified by the vendors can be used&#41;.</em></p> <p>Back to our hardware:</p> <table><tr><th align=center >Device<th align=center >TFLOP/s &#40;FP64&#41;<th align=center >Memory BW TB/s<th align=center >Imbalance &#40;FP64&#41;<tr><td align=center >Tesla A100<td align=center >9.7<td align=center >1.55<td align=center >9.7 / 1.55 × 8 &#61; 50<tr><td align=center >AMD EPYC 7282<td align=center >0.7<td align=center >0.085<td align=center >0.7 / 0.085 × 8 &#61; 66</table> <p><em>&#40;here computed with double precision values&#41;</em></p> <p><strong>Meaning:</strong> we can do 50 &#40;GPU&#41; and 66 &#40;CPU&#41; floating point operations per number accessed from main memory. Floating point operations are &quot;for free&quot; when we work in memory-bounded regimes</p> <p>➡ Requires to re-think the numerical implementation and solution strategies</p> <h3 id=on_the_scientific_application_side ><a href="#on_the_scientific_application_side" class=header-anchor >On the scientific application side</a></h3> <ul> <li><p>Most algorithms require only a few operations or flops ...</p> <li><p>... compared to the amount of numbers or bytes accessed from main memory.</p> </ul> <p>First derivative example \(∂A / ∂x\):</p> <p>If we &quot;naively&quot; compare the &quot;cost&quot; of an isolated evaluation of a finite-difference first derivative, e.g., computing a flux \(q\):</p> \[q = -D~\frac{∂A}{∂x}~,\] <p>which in the discrete form reads <code>q&#91;ix&#93; &#61; -D*&#40;A&#91;ix&#43;1&#93;-A&#91;ix&#93;&#41;/dx</code>.</p> <p>The cost of evaluating <code>q&#91;ix&#93; &#61; -D*&#40;A&#91;ix&#43;1&#93;-A&#91;ix&#93;&#41;/dx</code>:</p> <p>1 reads &#43; 1 write &#61;&gt; \(2 × 8\) &#61; <strong>16 Bytes transferred</strong></p> <p>1 &#40;fused&#41; addition and division &#61;&gt; <strong>1 floating point operations</strong></p> <p>assuming:</p> <ul> <li><p>\(D\), \(∂x\) are scalars</p> <li><p>\(q\) and \(A\) are arrays of <code>Float64</code> &#40;read from main memory&#41;</p> </ul> <p>GPUs and CPUs perform 50 - 60 FLOP pro number accessed from main memory</p> <p>First derivative evaluation requires to transfer 2 numbers per FLOP</p> <p>The FLOP/s metric is no longer the most adequate for reporting the application performance of many modern applications on modern hardware.</p> <h2 id=effective_memory_throughput_metric_t_mathrmeff ><a href="#effective_memory_throughput_metric_t_mathrmeff" class=header-anchor >Effective memory throughput metric \(T_\mathrm{eff}\)</a></h2> <p>Need for a memory throughput-based performance evaluation metric: \(T_\mathrm{eff}\) &#91;GB/s&#93;</p> <p>➡ Evaluate the performance of iterative stencil-based solvers.</p> <p>The effective memory access \(A_\mathrm{eff}\) &#91;GB&#93;</p> <p>Sum of:</p> <ul> <li><p>twice the memory footprint of the unknown fields, \(D_\mathrm{u}\), &#40;fields that depend on their own history and that need to be updated every iteration&#41;</p> <li><p>known fields, \(D_\mathrm{k}\), that do not change every iteration.</p> </ul> <p>The effective memory access divided by the execution time per iteration, \(t_\mathrm{it}\) &#91;sec&#93;, defines the effective memory throughput, \(T_\mathrm{eff}\) &#91;GB/s&#93;:</p> \[ A_\mathrm{eff} = 2~D_\mathrm{u} + D_\mathrm{k} \] \[ T_\mathrm{eff} = \frac{A_\mathrm{eff}}{t_\mathrm{it}} \] <p>The upper bound of \(T_\mathrm{eff}\) is \(T_\mathrm{peak}\) as measured, e.g., by <a href="https://www.researchgate.net/publication/51992086_Memory_bandwidth_and_machine_balance_in_high_performance_computers">McCalpin, 1995</a> for CPUs or a GPU analogue.</p> <p>Defining the \(T_\mathrm{eff}\) metric, we assume that:</p> <ol> <li><p>we evaluate an iterative stencil-based solver,</p> <li><p>the problem size is much larger than the cache sizes and</p> <li><p>the usage of time blocking is not feasible or advantageous &#40;reasonable for real-world applications&#41;.</p> </ol> <div class=note ><div class=title >💡 Note</div> <div class=messg >Fields within the effective memory access that do not depend on their own history; such fields can be re-computed on the fly or stored on-chip.</div></div> <p>As first task, we&#39;ll compute the \(T_\mathrm{eff}\) for the 2D diffusion code <a href="https://github.com/eth-vaw-glaciology/course-101-0250-00/blob/main/scripts/"><code>diffusion_2D.jl</code></a> we are already familiar with &#40;download the script if needed to get started&#41;.</p> <p><strong>To-do list:</strong></p> <ul> <li><p>copy <a href="https://github.com/eth-vaw-glaciology/course-101-0250-00/blob/main/scripts/"><code>diffusion_2D.jl</code></a> and rename it to <a href="https://github.com/eth-vaw-glaciology/course-101-0250-00/blob/main/scripts/"><code>diffusion_2D_Teff.jl</code></a></p> <li><p>add a timer</p> <li><p>include the performance metric formulas</p> <li><p>deactivate visualisation</p> </ul> <p>💻 Let&#39;s get started</p> <h3 id=timer_and_performance ><a href="#timer_and_performance" class=header-anchor >Timer and performance</a></h3> <ul> <li><p>Use <code>Base.time&#40;&#41;</code> to return the current timestamp</p> <li><p>Define <code>t_tic</code>, the starting time, after 11 time steps to allow for &quot;warmup&quot;</p> <li><p>Record the exact number of iterations &#40;introduce e.g. <code>niter</code>&#41;</p> <li><p>Compute the elapsed time <code>t_toc</code> at the end of the time loop and report:</p> </ul> <pre><code class=language-julia >t_toc &#61; Base.time&#40;&#41; - t_tic
A_eff &#61; &#40;1*2&#41;/1e9*nx*ny*sizeof&#40;Float64&#41;  # Effective main memory access per iteration &#91;GB&#93;
t_it  &#61; t_toc/niter                      # Execution time per iteration &#91;s&#93;
T_eff &#61; A_eff/t_it                       # Effective memory throughput &#91;GB/s&#93;</code></pre> <ul> <li><p>Report <code>t_toc</code>, <code>T_eff</code> and <code>niter</code> at the end of the code, formatting output using <code>@printf&#40;&#41;</code> macro.</p> <li><p>Round <code>T_eff</code> to the 3rd significant digit.</p> </ul> <pre><code class=language-julia >@printf&#40;&quot;Time &#61; &#37;1.3f sec, T_eff &#61; &#37;1.2f GB/s &#40;niter &#61; &#37;d&#41;\n&quot;, t_toc, round&#40;T_eff, sigdigits&#61;3&#41;, niter&#41;</code></pre>
<h3 id=deactivate_visualisation ><a href="#deactivate_visualisation" class=header-anchor >Deactivate visualisation</a></h3>
<ul>
<li><p>Use keyword arguments &#40;&quot;kwargs&quot;&#41; to allow for default behaviour</p>

<li><p>Define a <code>do_visu</code> flag set to <code>false</code></p>

</ul>
<pre><code class=language-julia >@views function diffusion_2D&#40;; do_visu&#61;false&#41;


   if do_visu &amp;&amp; &#40;it &#37; nout &#61;&#61; 0&#41;
       ...
   end
    return
end

diffusion_2D&#40;; do_visu&#61;false&#41;</code></pre>
<p>So far so good, we have now a timer.</p>
<p>Let&#39;s also boost resolution to <code>nx &#61; ny &#61; 512</code> and set <code>ttot &#61; 0.1</code> to have the code running ~1 sec.</p>
<p>In the next part, we&#39;ll work on a multi-threading implementation.</p>
<h2 id=parallel_computing_on_cpus ><a href="#parallel_computing_on_cpus" class=header-anchor >Parallel computing on CPUs</a></h2>
<p><em>Towards implementing shared memory parallelisation using multi-threading capabilities of modern multi-core CPUs.</em></p>
<p>We&#39;ll work it out in 4 steps:</p>
<ol>
<li><p>Precomputing scalars, removing divisions and casual arrays</p>

<li><p>Replacing flux arrays by macros</p>

<li><p>Back to loops I</p>

<li><p>Back to loops II - compute functions &#40;kernels&#41;</p>

</ol>
<h3 id=precomputing_scalars_removing_divisions_and_casual_arrays ><a href="#precomputing_scalars_removing_divisions_and_casual_arrays" class=header-anchor ><ol>
<li><p>Precomputing scalars, removing divisions and casual arrays</p>

</ol>
</a></h3>
<p>As first, duplicate <a href="https://github.com/eth-vaw-glaciology/course-101-0250-00/blob/main/scripts/"><code>diffusion_2D_Teff.jl</code></a> and rename it as <a href="https://github.com/eth-vaw-glaciology/course-101-0250-00/blob/main/scripts/"><code>diffusion_2D_perf.jl</code></a></p>
<ul>
<li><p>First, replace <code>D/dx</code> and <code>D/dy</code> in the flux calculations by precomputed <code>D_dx &#61; D/dx</code> and <code>D_dy &#61; D/dy</code> in the fluxes.</p>

<li><p>Then, replace divisions <code>/dx, /dy</code> by inverse multiplications <code>*_dx, *_dy</code> where <code>_dx, _dy &#61; 1.0/dx, 1.0/dy</code>.</p>

<li><p>Remove the <code>dCdt</code> array as we do not actually need it in the algorithm.</p>

</ul>
<h3 id=ol_start2_replacing_flux_arrays_by_macros ><a href="#ol_start2_replacing_flux_arrays_by_macros" class=header-anchor ><ol start=2 >
<li><p>Replacing flux arrays by macros</p>

</ol>
</a></h3>
<p>As first, duplicate <code>diffusion_2D_perf.jl</code> and rename it as <code>diffusion_2D_perf2.jl</code></p>
<p>Storing flux calculations in <code>qx</code> and <code>qy</code> arrays is not needed and produces additional read/write we want to avoid.</p>
<p>Let&#39;s create macros and call them in the time loop:</p>
<pre><code class=language-julia >macro qx&#40;&#41;  esc&#40;:&#40; .-D_dx.*diff&#40;C&#91;:,2:end-1&#93;,dims&#61;1&#41; &#41;&#41; end
macro qy&#40;&#41;  esc&#40;:&#40; .-D_dy.*diff&#40;C&#91;2:end-1,:&#93;,dims&#61;2&#41; &#41;&#41; end</code></pre>
<p>Macro will be expanded at preprocessing stage &#40;copy-paste&#41;</p>
<p>Advantages of using macros vs functions:</p>
<ul>
<li><p>easier syntax &#40;no need to specify indices&#41;</p>

<li><p>there can be a performance advantage &#40;if functions are not inlined&#41;</p>

</ul>
<p>Also, we now have to ensure <code>C</code> is not read and written back in the same &#40;will become important when enabling multi-threading&#41;.</p>
<p>Define <code>C2</code>, a copy of <code>C</code>, modify the physics computation line, and implement a pointer swap</p>
<pre><code class=language-julia >C2      &#61; copy&#40;C&#41;
# &#91;...&#93;
C2&#91;2:end-1,2:end-1&#93; .&#61; C&#91;2:end-1,2:end-1&#93; .- dt.*&#40;diff&#40;@qx&#40;&#41;,dims&#61;1&#41;.*_dx .&#43; diff&#40;@qy&#40;&#41;,dims&#61;2&#41;.*_dy&#41;
C, C2 &#61; C2, C # pointer swap</code></pre>
<h3 id=ol_start3_back_to_loops_i ><a href="#ol_start3_back_to_loops_i" class=header-anchor ><ol start=3 >
<li><p>Back to loops I</p>

</ol>
</a></h3>
<p>As first, duplicate <a href="https://github.com/eth-vaw-glaciology/course-101-0250-00/blob/main/scripts/"><code>diffusion_2D_perf2.jl</code></a> and rename it as <a href="https://github.com/eth-vaw-glaciology/course-101-0250-00/blob/main/scripts/"><code>diffusion_2D_perf_loop.jl</code></a></p>
<p>The goal is now to write out the diffusion physics in a loop fashion over \(x\) and \(y\) dimensions.</p>
<p>Implement a nested loop, taking car of bounds and staggering.</p>
<pre><code class=language-julia >for iy&#61;1:size&#40;C,2&#41;-2
    for ix&#61;1:size&#40;C,1&#41;-2
        C2&#91;ix&#43;1,iy&#43;1&#93; &#61; C&#91;ix&#43;1,iy&#43;1&#93; - dt*&#40; &#40;@qx&#40;ix&#43;1,iy&#41; - @qx&#40;ix,iy&#41;&#41;*_dx &#43; &#40;@qy&#40;ix,iy&#43;1&#41; - @qy&#40;ix,iy&#41;&#41;*_dy &#41;
    end
end</code></pre>
<p>Note that macros can take arguments, here <code>ix,iy</code>, and need updated definition.</p>
<p>Macro argument can be used in definition appending <code>&#36;</code>.</p>
<pre><code class=language-julia >macro qx&#40;ix,iy&#41;  esc&#40;:&#40; -D_dx*&#40;C&#91;&#36;ix&#43;1,&#36;iy&#43;1&#93; - C&#91;&#36;ix,&#36;iy&#43;1&#93;&#41; &#41;&#41; end
macro qy&#40;ix,iy&#41;  esc&#40;:&#40; -D_dy*&#40;C&#91;&#36;ix&#43;1,&#36;iy&#43;1&#93; - C&#91;&#36;ix&#43;1,&#36;iy&#93;&#41; &#41;&#41; end</code></pre>
<p>Performance is already quite better with the loop version. Reasons are that <code>diff&#40;&#41;</code> are allocating tmp and that Julia is overall well optimised for executing loops.</p>
<p>Let&#39;s now implement the final step.</p>
<h3 id=ol_start4_back_to_loops_ii ><a href="#ol_start4_back_to_loops_ii" class=header-anchor ><ol start=4 >
<li><p>Back to loops II</p>

</ol>
</a></h3>
<p>Duplicate <a href="https://github.com/eth-vaw-glaciology/course-101-0250-00/blob/main/scripts/"><code>diffusion_2D_perf2_loop.jl</code></a> and rename it as <a href="https://github.com/eth-vaw-glaciology/course-101-0250-00/blob/main/scripts/"><code>diffusion_2D_perf_loop_fun.jl</code></a></p>
<p>In this last step, the goal is to define a <code>compute</code> function to hold the physics calculations, and to call it within the time loop.</p>
<p>Create a <code>compute&#33;&#40;&#41;</code> function that takes input and output arrays and needed scalars as argument and returns nothing.</p>
<pre><code class=language-julia >function compute&#33;&#40;C2, C, D_dx, D_dy, dt, _dx, _dy&#41;
    for iy&#61;1:size&#40;C,2&#41;-2
        for ix&#61;1:size&#40;C,1&#41;-2
            C2&#91;ix&#43;1,iy&#43;1&#93; &#61; C&#91;ix&#43;1,iy&#43;1&#93; - dt*&#40; &#40;@qx&#40;ix&#43;1,iy&#41; - @qx&#40;ix,iy&#41;&#41;*_dx &#43; &#40;@qy&#40;ix,iy&#43;1&#41; - @qy&#40;ix,iy&#41;&#41;*_dy &#41;
        end
    end
    return
end</code></pre>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >Functions that modify arguments take a <code>&#33;</code> in their name, a Julia convention.</div></div>
<p>The <code>compute&#33;&#40;&#41;</code> function can then be called within the time loop</p>
<pre><code class=language-julia >compute&#33;&#40;C2, C, D_dx, D_dy, dt, _dx, _dy&#41;</code></pre>
<p>This last implementation executes a bit faster as previous one, as functions allow Julia to further optimise during just-ahead-of-time compilation.</p>
<p>Let&#39;s now see how to implement multi-threading and use <a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions">advanced vector extensions &#40;AVX&#41;</a>.</p>
<h2 id=shared_memory_parallelisation ><a href="#shared_memory_parallelisation" class=header-anchor >Shared memory parallelisation</a></h2>
<h3 id=multi-threading_native ><a href="#multi-threading_native" class=header-anchor >Multi-threading &#40;native&#41;</a></h3>
<p>Julia ships with it&#39;s <code>base</code> feature the possibility to enable <a href="https://docs.julialang.org/en/v1/manual/multi-threading/">multi-threading</a>.</p>
<p>The only 2 modifications needed to enable it in our code are:</p>
<ol>
<li><p>Place <code>Threads.@threads</code> in front of the outer loop definition</p>

<li><p>Export the desired amount of threads, e.g., <code>export JULIA_NUM_THREADS&#61;4</code>, to be activate prior to launching Julia &#40;or executing the script from the shell&#41;</p>

</ol>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >For optimal performance, the numbers of threads should be identical to the  number of physical cores of the target CPU.</div></div>
<h3 id=multi-threading_and_avx ><a href="#multi-threading_and_avx" class=header-anchor >Multi-threading and AVX</a></h3>
<p>Relying on Julia&#39;s <a href="https://github.com/JuliaSIMD/LoopVectorization.jl">LoopVectorization.jl</a> package, it is possible to combine multi-threading with AVX optimisations, relying on extensions to the x86 instruction set architecture.</p>
<p>To enable it in our code:</p>
<ol>
<li><p>Add <code>using LoopVectorization</code> at the top of the script</p>

<li><p>Replace <code>Threads.@threads</code> by <code>@tturbo</code> in front of the outer loop in the <code>compute&#33;&#40;&#41;</code> kernel</p>

</ol>
<p>And here we go 🚀</p>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >For optimal performance assessment, bound-checking should be deactivated. This can be achieved by adding <code>@inbounds</code> in front of the compute statement, or running the scripts &#40;or launching Julia&#41; with the <code>--check-bounds&#61;no</code> option.</div></div>
<h3 id=wrapping-up ><a href="#wrapping-up" class=header-anchor >Wrapping-up</a></h3>
<ul>
<li><p>We discussed main performance limiters</p>

<li><p>We implemented the effective memory throughput metric \(T_\mathrm{eff}\)</p>

<li><p>We optimised the Julia 2D diffusion code &#40;multi-threading and AVX&#41;</p>

</ul>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >Various timing and benchmarking tools are available in Julia&#39;s ecosystem to <a href="https://docs.julialang.org/en/v1/manual/performance-tips/">track performance issues</a>. Julia&#39;s base exposes the <code>@time</code> macro which returns timing and allocation estimation. <a href="https://github.com/JuliaCI/BenchmarkTools.jl">BenchmarkTools.jl</a> package provides finer grained timing and benchmarking tooling, namely the <code>@btime</code> and <code>@benchmark</code> macros, among others.</div></div>

<p><a href="#content">⤴ <em><strong>back to Content</strong></em></a></p>
<h1 id=unit_testing_in_julia ><a href="#unit_testing_in_julia" class=header-anchor >Unit testing in Julia</a></h1>
<h3 id=the_julia_test_module ><a href="#the_julia_test_module" class=header-anchor >The Julia <code>Test</code> module</a></h3>
<p><a href="https://docs.julialang.org/en/v1/stdlib/Test/#Basic-Unit-Tests">Basic unit tests</a> in Julia</p>
<ul>
<li><p>Provides simple <em>unit testing</em> functionality</p>

<li><p>A way to assess if code is correct by checking that results are as expected</p>

<li><p>Helpful to ensure the code still works after changes</p>

<li><p>Can be used when developing</p>

<li><p>Should be used in package for CI</p>

</ul>
<h2 id=basic_unit_tests ><a href="#basic_unit_tests" class=header-anchor >Basic unit tests</a></h2>
<p>Simple unit testing can be performed with the <code>@test</code> and <code>@test_throws</code> macros:</p>
<pre><code class=language-julia >using Test

@test true</code></pre><pre><code class="plaintext code-output">Test Passed</code></pre>
<p>Or another example</p>
<pre><code class=language-julia >@test &#91;1, 2&#93; &#43; &#91;2, 1&#93; &#61;&#61; &#91;3, 3&#93;</code></pre><pre><code class="plaintext code-output">Test Passed</code></pre>
<p>Testing an expression which is a call using infix syntax such as approximate comparisons</p>
<pre><code class=language-julia >@test π ≈ 3.14 atol&#61;0.01</code></pre><pre><code class="plaintext code-output">Test Passed</code></pre>
<p>For example, suppose we want to check our new function <code>square&#33;&#40;x&#41;</code> works as expected:</p>
<pre><code class=language-julia >square&#33;&#40;x&#41; &#61; x^2</code></pre><pre><code class="plaintext code-output">square! (generic function with 1 method)</code></pre>
<p>If the condition is true, a <code>Pass</code> is returned:</p>
<pre><code class=language-julia >@test square&#33;&#40;5&#41; &#61;&#61; 25</code></pre><pre><code class="plaintext code-output">Test Passed</code></pre>
<p>If the condition is false, then a <code>Fail</code> is returned and an exception is thrown:</p>
<pre><code class=language-julia >@test square&#33;&#40;5&#41; &#61;&#61; 20</code></pre>
<pre><code class=language-julia >Test Failed at none:1
  Expression: square&#33;&#40;5&#41; &#61;&#61; 20
   Evaluated: 25 &#61;&#61; 20
Test.FallbackTestSetException&#40;&quot;There was an error during testing&quot;&#41;</code></pre>
<h2 id=working_with_a_test_sets ><a href="#working_with_a_test_sets" class=header-anchor >Working with a test sets</a></h2>
<p>The <code>@testset</code> macro can be used to group <a href="https://docs.julialang.org/en/v1/stdlib/Test/#Working-with-Test-Sets">tests into sets</a>.</p>
<p>All the tests in a test set will be run, and at the end of the test set a summary will be printed.</p>
<p>If any of the tests failed, or could not be evaluated due to an error, the test set will then throw a <code>TestSetException</code>.</p>
<pre><code class=language-julia >@testset &quot;trigonometric identities&quot; begin
    θ &#61; 2/3*π
    @test sin&#40;-θ&#41; ≈ -sin&#40;θ&#41;
    @test cos&#40;-θ&#41; ≈ cos&#40;θ&#41;
    @test sin&#40;2θ&#41; ≈ 2*sin&#40;θ&#41;*cos&#40;θ&#41;
    @test cos&#40;2θ&#41; ≈ cos&#40;θ&#41;^2 - sin&#40;θ&#41;^2
end;</code></pre><pre><code class="plaintext code-output">Test Summary:            | Pass  Total
trigonometric identities |    4      4
</code></pre>
<p>Let&#39;s try it with our <code>square&#33;&#40;&#41;</code> function</p>
<pre><code class=language-julia >square&#33;&#40;x&#41; &#61; x^2

@testset &quot;Square Tests&quot; begin
    @test square&#33;&#40;5&#41; &#61;&#61; 25
    @test square&#33;&#40;&quot;a&quot;&#41; &#61;&#61; &quot;aa&quot;
    @test square&#33;&#40;&quot;bb&quot;&#41; &#61;&#61; &quot;bbbb&quot;
end;</code></pre><pre><code class="plaintext code-output">Test Summary: | Pass  Total
Square Tests  |    3      3
</code></pre>
<p>If we now introduce a bug</p>
<pre><code class=language-julia >square&#33;&#40;x&#41; &#61; x^2

@testset &quot;Square Tests&quot; begin
    @test square&#33;&#40;5&#41; &#61;&#61; 25
    @test square&#33;&#40;&quot;a&quot;&#41; &#61;&#61; &quot;aa&quot;
    @test square&#33;&#40;&quot;bb&quot;&#41; &#61;&#61; &quot;bbbb&quot;
    @test square&#33;&#40;5&#41; &#61;&#61; 20
end;</code></pre>
<pre><code class=language-julia >Square Tests: Test Failed at none:6
  Expression: square&#33;&#40;5&#41; &#61;&#61; 20
   Evaluated: 25 &#61;&#61; 20
Stacktrace:
 &#91;...&#93;
Test Summary: | Pass  Fail  Total
Square Tests  |    3     1      4
Some tests did not pass: 3 passed, 1 failed, 0 errored, 0 broken.</code></pre>
<p>Then then the reporting tells us a test failed.</p>
<h3 id=wrapping-up__2 ><a href="#wrapping-up__2" class=header-anchor >Wrapping-up</a></h3>
<ul>
<li><p>The <code>Test</code> module provides simple <em>unit testing</em> functionality.</p>

<li><p>Tests can be grouped into sets using <code>@testset</code>.</p>

<li><p>We&#39;ll later see how tests can be used in CI.</p>

</ul>

<p><a href="#content">⤴ <em><strong>back to Content</strong></em></a></p>
<h1 id=exercises_-_lecture_5 ><a href="#exercises_-_lecture_5" class=header-anchor >Exercises - lecture 5</a></h1>
<div class=warning ><div class=title >⚠️ Warning&#33;</div>
<div class=messg >Exercises have to be handed in as monolithic Julia scripts &#40;one code per script&#41; and uploaded to your private &#40;shared&#41; GitHub repository, in a <strong>specific folder for each lecture</strong>. The git commit hash &#40;or SHA&#41; of the final push needs to be uploaded on Moodle &#40;<a href="/course-101-0250-00/homework">more</a>&#41;.</div></div>
<h2 id=exercise_1_-_performance_implementation_diffusion_2d ><a href="#exercise_1_-_performance_implementation_diffusion_2d" class=header-anchor >Exercise 1 - <strong>Performance implementation: Diffusion 2D</strong></a></h2>
<p>👉 See <a href="/course-101-0250-00/logistics/#submission">Logistics</a> for submission details.</p>
<p>The goal of this exercise is to:</p>
<ul>
<li><p>Finalise the script discussed in class</p>

</ul>
<p>In this first exercise, you will terminate the performance oriented implementation of the 2D diffusion scripts from lecture 5.</p>
<p>👉 If needed, download the <a href="https://github.com/eth-vaw-glaciology/course-101-0250-00/blob/main/scripts/"><code>diffusion_2D.jl</code></a> to get you started.</p>
<h3 id=task_1 ><a href="#task_1" class=header-anchor >Task 1</a></h3>
<p>Create a new folder in your GitHub repository for this week&#39;s &#40;lecture 5&#41; exercises. In there, create a new subfolder <code>diffusion2D</code> where you will add following script:</p>
<ul>
<li><p><code>diffusion_2D_Teff.jl</code> &#40;<code>T_eff</code> implementation&#41;</p>

<li><p><code>diffusion_2D_perf.jl</code> &#40;scalar precomputations and removing <code>dCdt</code>&#41;</p>

<li><p><code>diffusion_2D_perf2.jl</code> &#40;flux computation as macros&#41;</p>

<li><p><code>diffusion_2D_loop.jl</code> &#40;loop version&#41;</p>

<li><p><code>diffusion_2D_loop_fun.jl</code> &#40;physics computations in <code>compute&#33;&#40;&#41;</code> function&#41;</p>

</ul>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >Refer to <a href="#timer_and_performance">this section</a> in lecture 5 to capture the starting point describing which features are specific to each version of the diffusion 2D codes.</div></div>

<p><a href="#content">⤴ <em><strong>back to Content</strong></em></a></p>
<hr />
<h2 id=exercise_2_-_performance_implementation_acoustic_2d ><a href="#exercise_2_-_performance_implementation_acoustic_2d" class=header-anchor >Exercise 2 - <strong>Performance implementation: Acoustic 2D</strong></a></h2>
<p>👉 See <a href="/course-101-0250-00/logistics/#submission">Logistics</a> for submission details.</p>
<p>The goal of this exercise is to:</p>
<ul>
<li><p>Apply the optimisation steps done for the diffusion 2D to the acoustic wave propagation 2D code &#40;velocity-pressure formulation&#41;</p>

</ul>
<p>For this second exercise, you will implement a performance oriented implementation of the 2D acoustic scripts from lecture 5.</p>
<p>👉 If needed, download the <a href="https://github.com/eth-vaw-glaciology/course-101-0250-00/blob/main/scripts/"><code>acoustic_2D.jl</code></a> to get you started.</p>
<h3 id=task_1__2 ><a href="#task_1__2" class=header-anchor >Task 1</a></h3>
<p>In the folder in your GitHub repository for this week&#39;s &#40;lecture 5&#41; exercises, create a new subfolder <code>acoustic2D</code> where you will add following script:</p>
<ul>
<li><p><code>acoustic_2D_Teff.jl</code></p>
<ul>
<li><p>Implement the <code>T_eff</code> metric to the acoustic wave in 2D. Since we are using the velocity-pressure formulation, think about how many arrays are read / written at every iterations and define <code>A_Eff</code> accordingly.</p>

<li><p>Use <code>@printf&#40;&#41;</code> to report <code>t_toc</code>, <code>T_eff</code> and <code>niter</code>.</p>

<li><p>Boost the number of grid points to <code>nx &#61; ny &#61; 512</code>.</p>

<li><p>Implement a flag to deactivate visualisation using kwargs.</p>

</ul>

<li><p><code>acoustic_2D_perf.jl</code></p>
<ul>
<li><p>Replace divisions by multiplications.</p>

<li><p>When possible, fuse scalar computations in preprocessing.</p>

</ul>

<li><p><code>acoustic_2D_perf_loop.jl</code></p>
<ul>
<li><p>Perform the computations of <code>Vx</code>, <code>Vy</code> and <code>P</code> in nested loops. Take care of the staggering and loop range.</p>

</ul>

<li><p><code>acoustic_2D_perf_loop_fun.jl</code></p>
<ul>
<li><p>Move the physics computations inside functions &#40;kernels&#41; and call them within the time loop. Use the minimal amount of functions that would ensure correct results.</p>

<li><p>Implement multi-threading using both <code>Threads.@threads</code> and <code>@tturbo</code> &#40;the latter from <a href="https://github.com/JuliaSIMD/LoopVectorization.jl">LoopVectorization.jl</a>&#41;.</p>

</ul>

</ul>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >Refer to <a href="#timer_and_performance">this section</a> in lecture 5 to capture the starting point describing which features are specific to each version of the diffusion 2D codes.</div></div>

<p><a href="#content">⤴ <em><strong>back to Content</strong></em></a></p>
<hr />
<h2 id=exercise_3_-_performance_evaluation ><a href="#exercise_3_-_performance_evaluation" class=header-anchor >Exercise 3 - <strong>Performance evaluation</strong></a></h2>
<p>👉 See <a href="/course-101-0250-00/logistics/#submission">Logistics</a> for submission details.</p>
<p>The goal of this exercise is to:</p>
<ul>
<li><p>Create a script to assess \(T_\mathrm{peak}\), using memory-copy</p>

<li><p>Assess \(T_\mathrm{peak}\) of your CPU</p>

<li><p>Perform a strong-scaling test: assess \(T_\mathrm{eff}\) for the diffusion 2D as function of number of grid points and implementation</p>

</ul>
<p>For this exercise, you will write a code to assess the peak memory throughput of your CPU and run a strong scaling benchmark using the diffusion 2D codes and report performance.</p>
<h3 id=task_1__3 ><a href="#task_1__3" class=header-anchor >Task 1</a></h3>
<p>In the <code>diffusion2D</code> folder, create a new script named <code>memcopy.jl</code>. You can use as starting point the <code>diffusion_2D_loop_fun.jl</code> script from lecture 5 &#40;or exercise 1&#41;.</p>
<ol>
<li><p>Rename the &quot;main&quot; function <code>memcopy</code></p>

<li><p>Modify the script to only keep following in the initialisation:</p>

</ol>
<pre><code class=language-julia ># Numerics
  nx, ny  &#61; 512, 512
  nt      &#61; 10000
  # Array initialisation
  C       &#61; rand&#40;Float64, nx, ny&#41;
  C2      &#61; copy&#40;C&#41;
  A       &#61; copy&#40;C&#41;</code></pre>
<ol start=3 >
<li><p>Modify the <code>compute&#33;&#40;&#41;</code> function to perform the following operation <code>C2 &#61; C &#43; A</code>, replacing the previous calculations.</p>

<li><p>Update the <code>A_eff</code> formula accordingly.</p>

</ol>
<p>Then, create a <code>README.md</code> file in the <code>diffusion2D</code> folder to report the results for each of the following tasks &#40;including a .png of the figure when instructed&#41;</p>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >Use <code>&#33;&#91;fig_name&#93;&#40;./&lt;relative-path&gt;/my_fig.png&#41;</code> to insert a .png figure in the <code>README.md</code>.</div></div>
<h3 id=task_2 ><a href="#task_2" class=header-anchor >Task 2</a></h3>
<p>Report on a figure \(T_\mathrm{eff}\) of your <code>memcopy.jl</code> code as function of number of grid points <code>nx × ny</code> for the simple <code>for</code> loop, the <code>Threads.@threads</code>, and the <code>@tturbo</code> implementations. Vary <code>nx</code>and <code>ny</code> such that <code>nx &#61; ny &#61; 16 * 2 .^ &#40;1:8&#41;</code>.</p>
<p><em>&#40;\(T_\mathrm{eff}\) of your <code>memcopy.jl</code> code represents \(T_\mathrm{peak}\), the peak memory throughput you can achieve on your CPU for a given implementation.&#41;</em></p>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >For performance evaluation we only need the code to run a couple of seconds; adapt <code>nt</code> accordingly &#40;you could also, e.g., make <code>nt</code> function of <code>nx, ny</code>&#41;. Ensure also to implement &quot;warm-up&quot; iterations.</div></div>
<p>Add the above figure in a new section of the <code>diffusion2D/README.md</code>, and provide a minimal description of 1&#41; the performed test, and 2&#41; a short description of the result. Figure out the vendor-announced peak memory bandwidth for your CPU, add it to the figure and use it to discuss your results.</p>
<h3 id=task_3 ><a href="#task_3" class=header-anchor >Task 3</a></h3>
<p>Repeat the strong scaling benchmark you just realised in Task 2 using the <code>memcopy.jl</code> code on the various diffusion 2D codes &#40;<code>perf2</code>, <code>perf_loop</code>, <code>perf_loop_fun</code> - <code>for</code>, <code>Threads.@threads</code>, <code>@tturbo</code> for the latter&#41;.</p>
<p>Report on a figure \(T_\mathrm{eff}\) of the 5 diffusion 2D code implementations as function of number of grid points <code>nx × ny</code>. Vary <code>nx</code>and <code>ny</code> such that <code>nx &#61; ny &#61; 16 * 2 .^ &#40;1:8&#41;</code>.</p>
<p>On the same figure, report also the memory copy values for the <code>for</code>, <code>Threads.@threads</code>, <code>@tturbo</code> implementation &#40;as, e.g, dashed lines&#41;.</p>
<p>Add this second figure in a new section of the <code>diffusion2D/README.md</code>, and provide a minimal description of 1&#41; the performed test, and 2&#41; a short description of the result.</p>

<p><a href="#content">⤴ <em><strong>back to Content</strong></em></a></p>
<hr />
<h2 id=exercise_4_-_unit_tests ><a href="#exercise_4_-_unit_tests" class=header-anchor >Exercise 4 - <strong>Unit tests</strong></a></h2>
<p>👉 See <a href="/course-101-0250-00/logistics/#submission">Logistics</a> for submission details.</p>
<p>The goal of this exercise is to:</p>
<ul>
<li><p>Implement basic unit tests for the diffusion and acoustic 2D scripts</p>

<li><p>Group the tests in a test-set</p>

</ul>
<p>For this exercise, you will implement a test set of basic unit tests to verify the implementation of the diffusion and acoustic 2D solvers.</p>
<h3 id=task_1__4 ><a href="#task_1__4" class=header-anchor >Task 1</a></h3>
<p>In the <code>diffusion2D</code> folder, duplicate the <code>diffusion_2D_perf_loop_fun.jl</code> script and rename it <code>diffusion_2D_test.jl</code>.</p>
<p>Implement a test set in order to test <code>C&#91;xtest, ytest&#93;</code> and assess that the values returned are approximatively equal to the following ones for the given values of <code>nx &#61; ny</code>.</p>
<pre><code class=language-julia >xtest &#61; &#91;5, Int&#40;cld&#40;0.6*Lx, dx&#41;&#41;, nx-10&#93;
ytest &#61; Int&#40;cld&#40;0.5*Ly, dy&#41;&#41;</code></pre>
<p>for</p>
<pre><code class=language-julia >nx &#61; ny &#61; 16 * 2 .^ &#40;2:5&#41;</code></pre>
<p>should match</p>
<table><tr><th align=center ><code>nx, ny</code><th align=center ><code>C&#91;xtest, ytest&#93;</code><tr><td align=center ><code>64</code><td align=center ><code>&#91;1.28961441675812e-6  0.3403434055248243  0.000226725154067358&#93;</code><tr><td align=center ><code>128</code><td align=center ><code>&#91;1.42876853096198e-7  0.3606848631942946  2.784022638919167e-6&#93;</code><tr><td align=center ><code>256</code><td align=center ><code>&#91;3.82994869422046e-8  0.3515100977539851  2.070629144549965e-7&#93;</code><tr><td align=center ><code>512</code><td align=center ><code>&#91;1.56975129887789e-8  0.3467239448747831  4.938759153492403e-8&#93;</code></table>
<p>Report the output of the test set as code block in a new section of the <code>README.md</code> in the <code>diffusion2D</code> folder.</p>
<div class=note ><div class=title >💡 Note</div>
<div class=messg >Use triple backticks to generate code blocks in the <code>README.md</code> &#40;<a href="https://www.markdownguide.org/extended-syntax/#fenced-code-blocks">more</a>&#41;.</div></div>

<p><a href="#content">⤴ <em><strong>back to Content</strong></em></a></p>
<div class=page-foot >
  <div class=copyright >
    <a href="https://github.com/eth-vaw-glaciology/course-101-0250-00/"><b>Edit this page on <img class=github-logo  src="https://unpkg.com/ionicons@5.1.2/dist/svg/logo-github.svg"></b></a><br>
    Last modified: November 10, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
  </div>
</div>
</div>
    </div>  
    
        <script src="/course-101-0250-00/libs/katex/katex.min.js"></script>
<script src="/course-101-0250-00/libs/katex/auto-render.min.js"></script>
<script>renderMathInElement(document.body)</script>

    
    
        <script src="/course-101-0250-00/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>